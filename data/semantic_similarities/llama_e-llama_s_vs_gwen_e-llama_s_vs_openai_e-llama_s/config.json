{
  "data_source_1": "llama_e-llama_s",
  "data_source_2": "gwen_e-llama_s",
  "data_source_3": "openai_e-llama_s",
  "embedding_filename": "embeddings.json",
  "similarity_metrics": [
    "cosine"
  ],
  "output_filename": "semantic_similarities.json",
  "description": "Configuration for calculating pairwise semantic similarities between embeddings from three data sources",
  "model_name_mapping": {
    "llama_e": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "gwen_e": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "openai_e": "openai/gpt-oss-20b"
  },
  "sae_id_1": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "sae_id_2": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "sae_id_3": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "llm_explainer_1": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
  "llm_explainer_2": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
  "llm_explainer_3": "openai/gpt-oss-20b"
}