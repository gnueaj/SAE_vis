{
  "activation_examples_path": "data/master/activation_examples.parquet",
  "output_path": "data/master/activation_embeddings.parquet",
  "sae_id": "google--gemma-scope-9b-pt-res--layer_30--width_16k--average_l0_120",

  "description": "Configuration for pre-computing embeddings of activation examples",

  "processing_parameters": {
    "num_quantiles": 4,
    "examples_per_quantile": 5,
    "target_examples_per_feature": 20,
    "token_window_size": 32
  },

  "model_parameters": {
    "sentence_transformer_model": "google/embeddinggemma-300m",
    "device": "cuda",
    "batch_size": 512
  },

  "processing_notes": {
    "expected_features": 16384,
    "processing_strategy": "quantile_based_sampling",
    "embedding_purpose": "pre_compute_for_downstream_similarity_analysis",
    "window_extraction": "symmetric_with_asymmetric_fallback",
    "primary_key_fields": [
      "feature_id",
      "sae_id"
    ]
  },

  "schema_info": {
    "table_name": "activation_embeddings",
    "version": "1.0",
    "field_descriptions": {
      "feature_id": "SAE feature index (0-16383)",
      "sae_id": "SAE model identifier",
      "prompt_ids": "List of prompt IDs selected via quantile sampling",
      "embeddings": "List of embeddings (768-dim vectors from google/embeddinggemma-300m)",
      "window_texts": "List of text windows used for embedding (for debugging/validation)"
    }
  },

  "performance_notes": {
    "embedding_dimension": 768,
    "expected_embeddings_per_feature": 20,
    "total_expected_embeddings": 327680,
    "batch_processing": true,
    "downstream_consumers": [
      "9_activation_example_similarity.py"
    ]
  }
}
