{
  "feature_id": 879,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1545",
      "text": "The word \\\"all\\\" is often used to emphasize inclusivity or totality, and is sometimes used in formal or legal contexts to convey a sense of universality or completeness.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_721",
      "text": "The words \\\"all\\\", \\\"each\\\", and \\\"every\\\" are used to denote totality or universality in a quantified or inclusive sense, often preceding or modifying a noun phrase to emphasize completeness or generalization.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2368",
      "text": "The highlighted words are universal determiners or pronouns—primarily “All” (capitalized or lowercase) and “every”—that signal totality or inclusiveness. They appear as standalone tokens or within common phrases such as “All of,” “All the,” “All rights reserved,” and “every solution.” These terms are used to refer to an entire set or group, often in formal, legal, or descriptive contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1545",
        "exp_721"
      ],
      "cosine_similarity": 0.9264347535093435,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1545",
        "exp_2368"
      ],
      "cosine_similarity": 0.9231393856017636,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_721",
        "exp_2368"
      ],
      "cosine_similarity": 0.9193477913443152,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.85,
      "score_detection": 0.825,
      "score_simulation": null,
      "score_embedding": 0.3475
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.9,
      "score_detection": 0.88,
      "score_simulation": null,
      "score_embedding": 0.36560000000000004
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8857142857142857,
      "score_detection": 0.875,
      "score_simulation": null,
      "score_embedding": 0.40624999999999994
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.95,
      "score_detection": 0.85,
      "score_simulation": null,
      "score_embedding": 0.40624999999999994
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.875,
      "score_detection": 0.825,
      "score_simulation": null,
      "score_embedding": 0.36560000000000004
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.9,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.3475
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.94,
      "score_detection": 0.9,
      "score_simulation": null,
      "score_embedding": 0.36560000000000004
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.875,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.3475
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.975,
      "score_detection": 0.85,
      "score_simulation": null,
      "score_embedding": 0.40624999999999994
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}