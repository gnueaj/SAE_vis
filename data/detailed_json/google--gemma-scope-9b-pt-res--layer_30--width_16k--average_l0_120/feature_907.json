{
  "feature_id": 907,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1567",
      "text": "Function words, possessive pronouns, and articles often precede nouns or noun phrases, sometimes indicating possession or relationship.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_743",
      "text": "Possessive pronouns (e.g., \\\"their\\\", \\\"its\\\", \\\"the\\\") and prepositions (e.g., \\\"in\\\", \\\"of\\\", \\\"to\\\") frequently appear in contextually dependent, grammatically required positions, often preceding or following nouns that denote abstract or physical entities, with high activation values indicating their role in syntactic and semantic structure.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2390",
      "text": "The highlighted tokens are usually short, high‑frequency function words that serve as the syntactic heads of phrases—determiners, prepositions, pronouns, or other linking words—often appearing at the beginning of a phrase and signalling the structure of the sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1567",
        "exp_743"
      ],
      "cosine_similarity": 0.9087661451640384,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1567",
        "exp_2390"
      ],
      "cosine_similarity": 0.8837134815116067,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_743",
        "exp_2390"
      ],
      "cosine_similarity": 0.8882766845139183,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6571428571428571,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.56375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.72,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.5744
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.72,
      "score_detection": 0.5428571428571428,
      "score_simulation": null,
      "score_embedding": 0.595
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.595
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.5744
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.56375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.58,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5744
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.725,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.56375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.595
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.3558181600726954,
      "z_score_fuzz": 0.3183142852554336,
      "z_score_detection": -0.8227425567134172
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.4147751483812902,
      "z_score_fuzz": -0.2124440604370861,
      "z_score_detection": -0.40150073047736795
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.5288140177857076,
      "z_score_fuzz": -0.10955859650284382,
      "z_score_detection": -0.37141202860336403
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.04953670379509608
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.06638988084438795
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.01594779755983324
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}