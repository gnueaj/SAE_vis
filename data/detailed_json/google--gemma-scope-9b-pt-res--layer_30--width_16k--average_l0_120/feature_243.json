{
  "feature_id": 243,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1028",
      "text": "Various suffixes and prefixes, often indicating a change in state, location, or time, and sometimes used in technical or scientific contexts, or as part of a citation or reference.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_204",
      "text": "The suffix \\\"-ate\\\" commonly appears in scientific and technical terms, often forming nouns or adjectives related to processes or states, and is frequently associated with chemical, biological, or engineering contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1851",
      "text": "The highlighted fragments are typically short, high‑frequency English words or common suffixes that appear embedded within larger words or phrases—such as “rate,” “gate,” “ate,” “at,” “later,” “note,” “states,” “agent,” and the “@” symbol. These tokens often function as connective or nominal elements in the surrounding context, indicating that the model flags frequent, functionally significant sub‑units rather than whole lexical items.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1028",
        "exp_204"
      ],
      "cosine_similarity": 0.8905467915807274,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1028",
        "exp_1851"
      ],
      "cosine_similarity": 0.8550964569613287,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_204",
        "exp_1851"
      ],
      "cosine_similarity": 0.8436914660996185,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.38,
      "score_detection": 0.37,
      "score_simulation": -0.017665426649571835,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.34285714285714286,
      "score_detection": null,
      "score_simulation": 0.040571227167118945,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.175,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5157894736842106,
      "score_detection": 0.26,
      "score_simulation": 0.03913905335572855,
      "score_embedding": 0.4248
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.42,
      "score_detection": 0.16,
      "score_simulation": -0.01824619143271253,
      "score_embedding": 0.4624
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.625,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}