{
  "feature_id": 850,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1523",
      "text": "The digit \\\"8\\\" often appears as the first digit in a phone number, and sometimes as a standalone digit in various contexts, including numerical data, codes, and mathematical expressions.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_699",
      "text": "The digit \\\"8\\\" frequently appears in numerical sequences, phone numbers, or identifiers, often in contexts involving contact information, dates, measurements, or technical codes.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2346",
      "text": "The highlighted tokens consistently form the semantic nucleus of each clause—whether that nucleus is the core of an idiom, the comparative suffix of an adjective, or the essential part of a contact detail such as a phone number, URL, or call‑to‑action phrase.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1523",
        "exp_699"
      ],
      "cosine_similarity": 0.9502726179101152,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1523",
        "exp_2346"
      ],
      "cosine_similarity": 0.8084074599569053,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_699",
        "exp_2346"
      ],
      "cosine_similarity": 0.8129929761846022,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.875,
      "score_detection": 0.8571428571428571,
      "score_simulation": null,
      "score_embedding": 0.75375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.84,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.7595999999999999
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.5875
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.825,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5875
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.875,
      "score_detection": 0.9,
      "score_simulation": null,
      "score_embedding": 0.7595999999999999
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.925,
      "score_detection": 0.85,
      "score_simulation": null,
      "score_embedding": 0.75375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.86,
      "score_detection": 0.81,
      "score_simulation": null,
      "score_embedding": 0.7595999999999999
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.875,
      "score_detection": 0.875,
      "score_simulation": null,
      "score_embedding": 0.75375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.575,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.5875
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 1.4076329749678096,
      "z_score_fuzz": 1.6737894450240205,
      "z_score_detection": 2.1192638487447097
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 1.440017799531685,
      "z_score_fuzz": 1.4451550807257045,
      "z_score_detection": 1.9504327993405792
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.4872950119345849,
      "z_score_fuzz": 0.016190303861229847,
      "z_score_detection": -0.12067284632000105
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 1.7335620895788466
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 1.6118685598659894
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.1276041564919379
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}