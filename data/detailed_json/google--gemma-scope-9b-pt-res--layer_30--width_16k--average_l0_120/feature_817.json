{
  "feature_id": 817,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1498",
      "text": "Punctuation marks used in various languages, including commas, periods, and question marks, often separating clauses or items in a list.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_674",
      "text": "Punctuation marks such as commas, periods, semicolons, and quotation marks are frequently activated in structured or segmented text, especially in lists, code comments, dialogue, and formatted documentation, indicating their role in syntactic and structural parsing.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2321",
      "text": "The highlighted tokens are primarily punctuation marks and a few conjunctions that serve as clause separators or linkers in the multilingual text.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1498",
        "exp_674"
      ],
      "cosine_similarity": 0.8939669289337738,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1498",
        "exp_2321"
      ],
      "cosine_similarity": 0.9039686697969099,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_674",
        "exp_2321"
      ],
      "cosine_similarity": 0.8765643676183873,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7714285714285715,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.3175
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.74,
      "score_detection": 0.54,
      "score_simulation": null,
      "score_embedding": 0.3548
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.825,
      "score_detection": 0.5714285714285714,
      "score_simulation": null,
      "score_embedding": 0.33
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.8,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.33
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7714285714285715,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.3548
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.75,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.3175
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.77,
      "score_detection": 0.63,
      "score_simulation": null,
      "score_embedding": 0.3548
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.825,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.3175
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.875,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.33
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.0073891987058403,
      "z_score_fuzz": 0.9225622480438396,
      "z_score_detection": 0.05484458127835328
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.8009013429395889,
      "z_score_fuzz": 0.7739499112499346,
      "z_score_detection": 0.33567246543571944
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.9381908556206353,
      "z_score_fuzz": 1.2736793075019681,
      "z_score_detection": -0.012019200663876645
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.009994123127882488
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.10290701124868838
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.10782308373915206
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}