{
  "feature_id": 298,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1074",
      "text": "Punctuation marks, particularly commas, parentheses, and colons, often used to separate or group items in code, data structures, and mathematical expressions.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_250",
      "text": "Closing punctuation marks such as parentheses, braces, or brackets are frequently activated when they appear at the end of syntactic or structural elements in code or markup, often signaling the end of a block, function, or expression.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1897",
      "text": "The highlighted tokens are code identifiers, keywords, and punctuation that form syntactic constructs in programming languages, such as function calls, class definitions, and API parameters.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1074",
        "exp_250"
      ],
      "cosine_similarity": 0.8668184619325785,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1074",
        "exp_1897"
      ],
      "cosine_similarity": 0.8616068643689493,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_250",
        "exp_1897"
      ],
      "cosine_similarity": 0.8523619136180104,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7333333333333333,
      "score_detection": 0.725,
      "score_simulation": null,
      "score_embedding": 0.709375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.75,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.5504000000000001
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.5249999999999999
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.5249999999999999
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6857142857142857,
      "score_detection": 0.6571428571428571,
      "score_simulation": null,
      "score_embedding": 0.5504000000000001
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.825,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.709375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.58,
      "score_simulation": null,
      "score_embedding": 0.5504000000000001
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.68,
      "score_simulation": null,
      "score_embedding": 0.709375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.5249999999999999
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 1.161978857015332,
      "z_score_fuzz": 0.6068290782985457,
      "z_score_detection": 1.2366619271072714
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.28191432965769736,
      "z_score_fuzz": 0.32647979826608775,
      "z_score_detection": 0.375790734601058
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.14130329650855997,
      "z_score_fuzz": -0.5553956068845605,
      "z_score_detection": -0.9397541751123203
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 1.0018232874737165
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.32806162084161433
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.45128216182944025
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}