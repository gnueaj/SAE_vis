{
  "feature_id": 339,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1109",
      "text": "Technical terms and phrases commonly used in scientific and laboratory settings, particularly in the fields of molecular biology, biochemistry, and immunology.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_285",
      "text": "Technical terms and compound words commonly found in scientific and laboratory protocols, often involving equipment, reagents, or experimental procedures, with frequent use of abbreviations, units, and specialized terminology.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1932",
      "text": "The activations consistently target sub‑word units that carry morphological or domain‑specific meaning—whole words, prefixes, suffixes, or split scientific terms—showing the model relies on these sub‑word components to encode and process specialized terminology.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1109",
        "exp_285"
      ],
      "cosine_similarity": 0.9227146959857182,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1109",
        "exp_1932"
      ],
      "cosine_similarity": 0.8308276969357271,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_285",
        "exp_1932"
      ],
      "cosine_similarity": 0.8458854863129204,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.533125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.48,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.5676
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.4,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.374375
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.374375
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.45,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5676
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.533125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.63,
      "score_detection": 0.51,
      "score_simulation": null,
      "score_embedding": 0.5676
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.58,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.533125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.675,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.374375
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.1862822195139434,
      "z_score_fuzz": -0.5439638886696444,
      "z_score_detection": -0.22598330287901286
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.3771312497429386,
      "z_score_fuzz": -0.8754837169022026,
      "z_score_detection": -0.3195925975981357
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.692536737668158,
      "z_score_fuzz": -0.9555057444066128,
      "z_score_detection": -0.35469608311780654
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.19455499067823792
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.27264835491913325
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.6675795217308592
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}