{
  "feature_id": 376,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1137",
      "text": "Code snippets in various programming languages, often including function calls, variable declarations, and control structures.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_313",
      "text": "The text contains programming syntax, identifiers, and structural elements such as parentheses, brackets, colons, and special tokens like `@`, `<<`, `>>`, and `nil`, often associated with code constructs, function definitions, type declarations, and language-specific syntax in languages like Swift, Objective-C, JavaScript, and Ruby.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1960",
      "text": "The highlighted tokens are identifiers and keywords that denote functions, methods, classes, variables, or properties in code, often part of method calls or property accesses, and are crucial for the behavior of the code.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1137",
        "exp_313"
      ],
      "cosine_similarity": 0.9037443491829849,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1137",
        "exp_1960"
      ],
      "cosine_similarity": 0.8690220694552739,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_313",
        "exp_1960"
      ],
      "cosine_similarity": 0.8799667437488183,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.475,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.486875
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.41,
      "score_detection": 0.42,
      "score_simulation": null,
      "score_embedding": 0.6028
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.37142857142857144,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.5275
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.325,
      "score_detection": 0.3,
      "score_simulation": null,
      "score_embedding": 0.5275
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.425,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.6028
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.4,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.486875
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.4,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.6028
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.37,
      "score_detection": 0.43,
      "score_simulation": null,
      "score_embedding": 0.486875
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.35,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.5275
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.06975164990131438,
      "z_score_fuzz": -1.595681964441898,
      "z_score_detection": -1.045064631671333
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.5719937838708755,
      "z_score_fuzz": -1.6185454008717302,
      "z_score_detection": -1.0099611461516618
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.15514296512560125,
      "z_score_fuzz": -2.049684487834269,
      "z_score_detection": -1.4078006487079313
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.9034994153381818
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.6855042543841722
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -1.100780723805533
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}