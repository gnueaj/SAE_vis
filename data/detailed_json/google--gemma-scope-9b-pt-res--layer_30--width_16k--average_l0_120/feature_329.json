{
  "feature_id": 329,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1101",
      "text": "Function words and nouns that are part of phrases or sentences that express purpose, ability, or permission, often used in formal or technical contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_277",
      "text": "The word \\\"to\\\" frequently appears in infinitive verb constructions, often following verbs of purpose or ability, and is commonly activated in contexts involving intention, capability, or functional purpose.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1924",
      "text": "The important tokens are typically short, highâ€‘frequency function words or key content words that serve as the core of a phrase, often forming common collocations or idiomatic expressions.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1101",
        "exp_277"
      ],
      "cosine_similarity": 0.8683917955849642,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1101",
        "exp_1924"
      ],
      "cosine_similarity": 0.8567348506951393,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_277",
        "exp_1924"
      ],
      "cosine_similarity": 0.8157385259342956,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.3975
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.67,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.5252
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5428571428571428,
      "score_detection": 0.4857142857142857,
      "score_simulation": null,
      "score_embedding": 0.42437499999999995
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.42437499999999995
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.5428571428571428,
      "score_simulation": null,
      "score_embedding": 0.5252
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.3975
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.66,
      "score_detection": 0.51,
      "score_simulation": null,
      "score_embedding": 0.5252
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.56,
      "score_simulation": null,
      "score_embedding": 0.3975
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.42437499999999995
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.5645198029605291,
      "z_score_fuzz": 0.016190303861229847,
      "z_score_detection": -0.2727879502385743
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.14241046999792373,
      "z_score_fuzz": 0.19909779529988308,
      "z_score_detection": -0.21929692468479003
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.415743365327339,
      "z_score_fuzz": -0.3430922686075527,
      "z_score_detection": -0.4466337832883727
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.2737058164459578
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.04073711353767226
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.4018231390744215
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}