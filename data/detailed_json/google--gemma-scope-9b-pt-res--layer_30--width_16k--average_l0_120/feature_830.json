{
  "feature_id": 830,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1509",
      "text": "Various tokens including nouns, adjectives, adverbs, and conjunctions that appear in different contexts, often representing a distinct object, concept, or relationship, and sometimes being part of a larger phrase or sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_685",
      "text": "Various tokens including nouns, adjectives, adverbs, and conjunctions that appear in different contexts, often representing a distinct object, concept, or relationship, and sometimes being part of a larger phrase or sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2332",
      "text": "The highlighted items are usually very short—single words, brief phrases, or even punctuation or digits—that function as key connectors, descriptors, or identifiers within the surrounding text, often appearing in legal, technical, or narrative contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1509",
        "exp_685"
      ],
      "cosine_similarity": 1.0,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1509",
        "exp_2332"
      ],
      "cosine_similarity": 0.8623876539100893,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_685",
        "exp_2332"
      ],
      "cosine_similarity": 0.8623876539100893,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.44,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.49,
      "score_detection": 0.46,
      "score_simulation": 0.044358865196279525,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.3333333333333333,
      "score_detection": 0.4888888888888889,
      "score_simulation": 0.08476166073300621,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.475,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.41,
      "score_detection": 0.38,
      "score_simulation": -0.010994098414826986,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.45714285714285713,
      "score_detection": 0.37142857142857144,
      "score_simulation": -0.03542167429251226,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.725,
      "score_detection": 0.675,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}