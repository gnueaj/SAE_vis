{
  "feature_id": 868,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1534",
      "text": "Scientific and technical terms, often representing names of organisms, chemicals, or biological processes, and sometimes abbreviations or prefixes/suffixes of these terms.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_710",
      "text": "Fragmented or partial word forms, often derived from scientific or technical terms, where individual morphemes or root components are activated in isolation, particularly in contexts involving biological, chemical, or computational terminology.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2357",
      "text": "The highlighted fragments are subâ€‘word pieces that, when joined, form a complete word; the model activates these pieces because they are split across token boundaries.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1534",
        "exp_710"
      ],
      "cosine_similarity": 0.9001154851398702,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1534",
        "exp_2357"
      ],
      "cosine_similarity": 0.8103742415061194,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_710",
        "exp_2357"
      ],
      "cosine_similarity": 0.871016440350659,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.575,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.21625000000000003
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.48,
      "score_simulation": null,
      "score_embedding": 0.2332
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.725,
      "score_detection": 0.45714285714285713,
      "score_simulation": null,
      "score_embedding": 0.293125
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.293125
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.2332
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.525,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.21625000000000003
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.63,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.2332
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.625,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.21625000000000003
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.293125
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.5678957776959994,
      "z_score_fuzz": -0.49823701580998087,
      "z_score_detection": -0.5887193199156124
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -1.474062824472462,
      "z_score_fuzz": -0.4868052975950656,
      "z_score_detection": -0.51851234887627
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.1423259677219897,
      "z_score_fuzz": -0.3839198336608233,
      "z_score_detection": -0.6305091836295061
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.8849507044738641
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.8264601569812658
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.7189183283374397
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}