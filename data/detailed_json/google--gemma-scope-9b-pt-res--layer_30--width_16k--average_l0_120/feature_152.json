{
  "feature_id": 152,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_951",
      "text": "Proper nouns, abbreviations, and technical terms, often representing names of institutions, locations, and organizations, as well as medical and technical terminology.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_127",
      "text": "Named entities, particularly proper nouns and acronyms, often appear in isolation or as partial tokens, with high activation values when they represent specific locations, institutions, or technical terms.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1775",
      "text": "The highlighted tokens are usually nouns or proper nouns that belong to named entities, technical terms, or key multiâ€‘word expressions, and occasionally morphological suffixes that signal grammatical roles; these tokens carry the core semantic or contextual weight of the sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_951",
        "exp_127"
      ],
      "cosine_similarity": 0.9098696408805254,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_951",
        "exp_1775"
      ],
      "cosine_similarity": 0.8731921561423654,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_127",
        "exp_1775"
      ],
      "cosine_similarity": 0.8898310940029327,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.475,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.43562500000000004
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.52,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.426
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6571428571428571,
      "score_detection": 0.5142857142857142,
      "score_simulation": null,
      "score_embedding": 0.455
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.455
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.426
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.43562500000000004
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.56,
      "score_detection": 0.52,
      "score_simulation": null,
      "score_embedding": 0.426
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.52,
      "score_detection": 0.44,
      "score_simulation": null,
      "score_embedding": 0.43562500000000004
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.455
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.3534648565506541,
      "z_score_fuzz": -0.7954616893977925,
      "z_score_detection": -0.8461448803931982
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.40674758072626216,
      "z_score_fuzz": -0.4868052975950656,
      "z_score_detection": -0.5068111870363802
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.2462074247685867,
      "z_score_fuzz": -0.13895444334119908,
      "z_score_detection": -0.730804856542851
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.6650238087805483
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.4667880217859026
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.3719889082175456
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}