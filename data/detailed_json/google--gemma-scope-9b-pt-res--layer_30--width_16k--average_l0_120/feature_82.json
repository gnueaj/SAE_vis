{
  "feature_id": 82,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_894",
      "text": "Past tense or past participle verb forms, often in formal or technical contexts, describing actions, states, or conditions.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_070",
      "text": "Nouns and adjectives denoting abstract or physical states, relationships, or conditions, often describing attributes, actions, or qualities in scientific, technical, or evaluative contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1718",
      "text": "The highlighted tokens are the core lexical items that carry the main semantic content of each phrase—typically nouns, adjectives, verbs, or key suffixes—while surrounding function words and punctuation are not marked. This pattern shows that the model focuses on the substantive words that define the meaning of the sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_894",
        "exp_070"
      ],
      "cosine_similarity": 0.8793341634188195,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_894",
        "exp_1718"
      ],
      "cosine_similarity": 0.8057551018920073,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_070",
        "exp_1718"
      ],
      "cosine_similarity": 0.8368104502023922,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5333333333333333,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6925000000000001
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.69,
      "score_detection": 0.57,
      "score_simulation": null,
      "score_embedding": 0.7968000000000001
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.775,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.755
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.755
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5714285714285714,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.7968000000000001
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.525,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.6925000000000001
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7222222222222222,
      "score_detection": 0.47,
      "score_simulation": null,
      "score_embedding": 0.7968000000000001
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6842105263157895,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": 0.6925000000000001
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.775,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.755
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 1.0685610938503063,
      "z_score_fuzz": -0.4581257238278206,
      "z_score_detection": -0.9982599843117715
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 1.6459520685532554,
      "z_score_fuzz": 0.09312758200605938,
      "z_score_detection": -0.027063551600879
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 1.41455280927633,
      "z_score_fuzz": 0.5306176235324406,
      "z_score_detection": -0.7057309383145148
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.12927487142976193
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.5706720329861452
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.4131464981647519
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}