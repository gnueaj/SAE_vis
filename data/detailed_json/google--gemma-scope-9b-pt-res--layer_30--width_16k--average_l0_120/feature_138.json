{
  "feature_id": 138,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_938",
      "text": "Code snippets from various programming languages, including Go, Java, and C++, with a focus on Kubernetes, cloud computing, and networking.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_114",
      "text": "The text latents involve structured code and documentation patterns, particularly in API and software development contexts, with frequent use of identifiers, type names, and syntactic elements like parentheses, dots, and special characters, often related to programming constructs, package paths, and metadata annotations.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1762",
      "text": "The highlighted tokens are domain‑specific identifiers—nouns and verbs that name resources, types, or actions in code and documentation, often appearing in function names, comments, or variable declarations.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_938",
        "exp_114"
      ],
      "cosine_similarity": 0.8577119749461702,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_938",
        "exp_1762"
      ],
      "cosine_similarity": 0.8330503964499407,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_114",
        "exp_1762"
      ],
      "cosine_similarity": 0.8880684674227439,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.34437500000000004
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.76,
      "score_detection": 0.81,
      "score_simulation": null,
      "score_embedding": 0.41
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.575,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.37812499999999993
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.525,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.37812499999999993
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.75,
      "score_detection": 0.725,
      "score_simulation": null,
      "score_embedding": 0.41
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.34437500000000004
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.74,
      "score_detection": 0.74,
      "score_simulation": null,
      "score_embedding": 0.41
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.61,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.34437500000000004
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.37812499999999993
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.8586127610726496,
      "z_score_fuzz": -0.24673921508183355,
      "z_score_detection": 0.4058794364750619
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.49532145987532444,
      "z_score_fuzz": 0.7020933967561778,
      "z_score_detection": 1.400478192865736
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.6717772347425971,
      "z_score_fuzz": -0.4410784247354021,
      "z_score_detection": -0.003661227921098684
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.23315751322647374
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.5357500432488631
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.3721722957996993
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}