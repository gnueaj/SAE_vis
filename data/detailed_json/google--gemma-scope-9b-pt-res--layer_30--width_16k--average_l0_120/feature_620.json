{
  "feature_id": 620,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1334",
      "text": "Prefixes or partial words of various lengths, often from proper nouns or technical terms, and sometimes from common words.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_510",
      "text": "Partial word fragments at the start of tokens, often representing names, places, or technical terms, with varying activation levels depending on context and familiarity.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2157",
      "text": "The model’s activations are triggered by sub‑word fragments that appear inside larger words—often proper nouns or technical terms—indicating that the network relies on sub‑word tokenization and that these partial tokens carry semantic or syntactic weight.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1334",
        "exp_510"
      ],
      "cosine_similarity": 0.9081388802700201,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1334",
        "exp_2157"
      ],
      "cosine_similarity": 0.8793492381505793,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_510",
        "exp_2157"
      ],
      "cosine_similarity": 0.903007436428787,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.486875
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.69,
      "score_detection": 0.46,
      "score_simulation": null,
      "score_embedding": 0.5352
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.85,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.42874999999999996
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.42874999999999996
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7142857142857143,
      "score_detection": 0.5714285714285714,
      "score_simulation": null,
      "score_embedding": 0.5352
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.486875
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.42,
      "score_simulation": null,
      "score_embedding": 0.5352
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.63,
      "score_detection": 0.38,
      "score_simulation": null,
      "score_embedding": 0.486875
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.85,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.42874999999999996
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.06975164990131438,
      "z_score_fuzz": 0.1990977952998823,
      "z_score_detection": -1.045064631671333
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.19776914446608768,
      "z_score_fuzz": 0.2546232837723309,
      "z_score_detection": -0.5268703216190495
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.3915239452475172,
      "z_score_fuzz": 0.7592519878307565,
      "z_score_detection": -0.6472251291150637
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.30523949542425505
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.024825964460210292
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.09316569551060812
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}