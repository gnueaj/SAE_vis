{
  "feature_id": 117,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_920",
      "text": "Adjectives and nouns that describe or modify a concept, object, or idea, often indicating a specific characteristic, origin, or relationship.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_096",
      "text": "Commonly activated tokens include function words (e.g., \\\"the\\\", \\\"to\\\", \\\"of\\\", \\\"and\\\"), comparative or derivational suffixes (e.g., \\\"er\\\", \\\"ing\\\", \\\"ised\\\"), and content words related to abstract concepts, spatial relations, or specific domains (e.g., \\\"spatial\\\", \\\"digital\\\", \\\"multiverse\\\", \\\"access\\\", \\\"structures\\\"), often appearing in academic or analytical contexts with a focus on relationships, processes, or systemic frameworks.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1744",
      "text": "The highlighted tokens are always part of a contiguous, semantically‑rich unit—an idiom, a comparative suffix, or a noun phrase—that carries a clear meaning or relationship in the sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_920",
        "exp_096"
      ],
      "cosine_similarity": 0.8205524980513249,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_920",
        "exp_1744"
      ],
      "cosine_similarity": 0.8411236595389774,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_096",
        "exp_1744"
      ],
      "cosine_similarity": 0.8425469617015678,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.37142857142857144,
      "score_detection": 0.45714285714285713,
      "score_simulation": null,
      "score_embedding": 0.5680000000000001
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.48,
      "score_simulation": 0.043743050169042196,
      "score_embedding": 0.22959999999999997
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.48,
      "score_detection": 0.475,
      "score_simulation": 0.06963602209861287,
      "score_embedding": 0.22959999999999997
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.475,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5680000000000001
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.56,
      "score_detection": 0.4631578947368421,
      "score_simulation": 0.045551109483620365,
      "score_embedding": 0.22959999999999997
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.54,
      "score_detection": 0.45,
      "score_simulation": -0.017750290448866564,
      "score_embedding": 0.5680000000000001
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}