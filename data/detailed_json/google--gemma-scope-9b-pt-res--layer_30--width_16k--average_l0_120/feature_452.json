{
  "feature_id": 452,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1195",
      "text": "Numerical digits embedded within text, often used to represent quantities, measurements, or codes.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_371",
      "text": "The digit \\\"6\\\" appears frequently in numerical contexts, often as part of multi-digit numbers, dates, or measurements, and is sometimes associated with specific formatting patterns like decimals or ranges. Other digits like \\\"2\\\", \\\"8\\\", and \\\"0\\\" also appear in similar numerical contexts, but \\\"6\\\" stands out as a recurring activation point in various numeric sequences.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2018",
      "text": "The highlighted tokens are numeric digits that appear within numeric values in the text.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1195",
        "exp_371"
      ],
      "cosine_similarity": 0.8773403252066425,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1195",
        "exp_2018"
      ],
      "cosine_similarity": 0.9129770350738257,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_371",
        "exp_2018"
      ],
      "cosine_similarity": 0.8748461632082223,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.85,
      "score_simulation": null,
      "score_embedding": 0.46124999999999994
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.96,
      "score_detection": 0.86,
      "score_simulation": null,
      "score_embedding": 0.45840000000000003
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 1.0,
      "score_detection": 0.8571428571428571,
      "score_simulation": null,
      "score_embedding": 0.286875
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.95,
      "score_detection": 0.875,
      "score_simulation": null,
      "score_embedding": 0.286875
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.875,
      "score_detection": 0.85,
      "score_simulation": null,
      "score_embedding": 0.45840000000000003
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.925,
      "score_detection": 0.825,
      "score_simulation": null,
      "score_embedding": 0.46124999999999994
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 1.0,
      "score_detection": 0.88,
      "score_simulation": null,
      "score_embedding": 0.45840000000000003
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.84,
      "score_detection": 0.83,
      "score_simulation": null,
      "score_embedding": 0.46124999999999994
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.975,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.286875
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}