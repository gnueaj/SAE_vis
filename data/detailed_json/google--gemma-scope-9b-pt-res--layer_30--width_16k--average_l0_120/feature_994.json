{
  "feature_id": 994,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1643",
      "text": "Special characters used in various programming languages and markup formats, including XML, HTML, JavaScript, and others, often serving as delimiters, operators, or indicators of specific syntax elements.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_819",
      "text": "Specialized punctuation and syntax symbols in code, markup, or technical documentation, such as brackets, colons, slashes, and quotation marks, are frequently activated in structured text formats like XML, JSON, code snippets, and markup languages.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2466",
      "text": "The highlighted tokens are the syntactic building blocks of programming languages—punctuation, operators, and keywords—that define the structure and meaning of code snippets.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1643",
        "exp_819"
      ],
      "cosine_similarity": 0.9114882005506478,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1643",
        "exp_2466"
      ],
      "cosine_similarity": 0.8806143830507421,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_819",
        "exp_2466"
      ],
      "cosine_similarity": 0.8733773862861209,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5142857142857142,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.623125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.52,
      "score_detection": 0.48,
      "score_simulation": null,
      "score_embedding": 0.6748
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6285714285714286,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.568125
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.325,
      "score_simulation": null,
      "score_embedding": 0.568125
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.6748
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.623125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.48,
      "score_simulation": null,
      "score_embedding": 0.6748
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.623125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.475,
      "score_detection": 0.325,
      "score_simulation": null,
      "score_embedding": 0.568125
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.6845102897274189,
      "z_score_fuzz": -1.0371608745131546,
      "z_score_detection": -0.764236747513966
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.9705762400416553,
      "z_score_fuzz": -0.509668734024897,
      "z_score_detection": -0.448305377836929
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.3800375801525172,
      "z_score_fuzz": -0.8901816403213807,
      "z_score_detection": -1.2907890303090286
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.3722957774332339
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.004200709393276454
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.6003110301592973
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}