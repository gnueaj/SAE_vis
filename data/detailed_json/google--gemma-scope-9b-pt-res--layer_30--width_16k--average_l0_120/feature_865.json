{
  "feature_id": 865,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1533",
      "text": "Conjunctions, nouns, and other parts of speech that are part of a phrase or sentence, often indicating a connection or relationship between entities, actions, or ideas.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_709",
      "text": "The word \\\"and\\\" frequently appears in sequences involving conjunctions, lists, or compound structures, often linking related concepts, items, or clauses, with high activation when connecting distinct but semantically linked elements.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2356",
      "text": "The activations consistently highlight high‑frequency function words that act as syntactic glue—especially conjunctions and prepositions such as “and” and “the”—and these words frequently appear in common collocations or multi‑word expressions.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1533",
        "exp_709"
      ],
      "cosine_similarity": 0.871025461474931,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1533",
        "exp_2356"
      ],
      "cosine_similarity": 0.8603898294272978,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_709",
        "exp_2356"
      ],
      "cosine_similarity": 0.8984421145416329,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5666666666666667,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.6
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.42,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.5831999999999999
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.575,
      "score_detection": 0.5428571428571428,
      "score_simulation": null,
      "score_embedding": 0.629375
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.629375
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7142857142857143,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.5831999999999999
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.57,
      "score_detection": 0.44,
      "score_simulation": null,
      "score_embedding": 0.5831999999999999
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.575,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.6
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.629375
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}