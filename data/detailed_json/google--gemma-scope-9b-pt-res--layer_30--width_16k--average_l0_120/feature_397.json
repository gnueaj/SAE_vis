{
  "feature_id": 397,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1153",
      "text": "Punctuation marks, often commas or periods, used to separate clauses or sentences, sometimes indicating a pause or a shift in thought.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_329",
      "text": "Commas and punctuation marks frequently appear in proximity to discourse markers, parenthetical expressions, or transitional phrases, often signaling pauses, interruptions, or shifts in thought, particularly in conversational or narrative text.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1976",
      "text": "The highlighted fragments are usually brief function words or punctuation that signal clause boundaries, connect ideas, or introduce quoted material, often appearing at the start or end of a phrase.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1153",
        "exp_329"
      ],
      "cosine_similarity": 0.9239815145202015,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1153",
        "exp_1976"
      ],
      "cosine_similarity": 0.8862031436432102,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_329",
        "exp_1976"
      ],
      "cosine_similarity": 0.8868936028971932,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.21000000000000002
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.72,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.22840000000000002
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.15375
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.775,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.15375
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.775,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.22840000000000002
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.675,
      "score_simulation": null,
      "score_embedding": 0.21000000000000002
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.86,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.22840000000000002
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.86,
      "score_detection": 0.86,
      "score_simulation": null,
      "score_embedding": 0.21000000000000002
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.15375
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.602494949238602,
      "z_score_fuzz": 0.5534810599622727,
      "z_score_detection": 1.0728456613488069
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -1.5006349882171803,
      "z_score_fuzz": 0.9421594792694098,
      "z_score_detection": -0.22598330287901286
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.913887493122024,
      "z_score_fuzz": 0.873569169979915,
      "z_score_detection": 0.34737362727560994
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.007943924024159147
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.2614862706089278
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.23098156528883307
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}