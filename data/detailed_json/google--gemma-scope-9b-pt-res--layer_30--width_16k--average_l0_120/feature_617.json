{
  "feature_id": 617,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1331",
      "text": "Tokens representing programming syntax elements, including operators, keywords, and symbols, often used in C++ and other programming languages.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_507",
      "text": "Patterns in code include identifiers with underscores and numeric suffixes, template syntax with angle brackets, and symbolic tokens representing programming constructs or constants.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2154",
      "text": "The highlighted fragments are code identifiers and syntactic elements that define behavior—function names, macros, template parameters, constants, and operators—often split across tokens, indicating the model is focusing on the structural components of code that drive execution.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1331",
        "exp_507"
      ],
      "cosine_similarity": 0.9006691090077256,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1331",
        "exp_2154"
      ],
      "cosine_similarity": 0.8776035107890027,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_507",
        "exp_2154"
      ],
      "cosine_similarity": 0.9006364615767709,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.35,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.47,
      "score_detection": 0.57,
      "score_simulation": 0.020336028483475332,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.26666666666666666,
      "score_detection": 0.4666666666666667,
      "score_simulation": 0.0020559229446980754,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.53,
      "score_detection": 0.8,
      "score_simulation": 0.044218604886226115,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.54,
      "score_detection": 0.69,
      "score_simulation": 0.41459807423413,
      "score_embedding": 0.21080000000000002
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.45,
      "score_detection": 0.675,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}