{
  "feature_id": 743,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1438",
      "text": "Sentence-ending punctuation marks.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_614",
      "text": "The period (\\\".\\\") is frequently activated at the end of sentences, especially in structured or punctuated text, often preceding or following quotation marks, parentheses, or other punctuation, and is strongly associated with sentence boundaries in both formal and informal writing.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2261",
      "text": "The highlighted tokens are primarily punctuation marks that signal sentence boundaries or emphasis, indicating that the model focuses on boundary cues rather than lexical content.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1438",
        "exp_614"
      ],
      "cosine_similarity": 0.8835802807169701,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1438",
        "exp_2261"
      ],
      "cosine_similarity": 0.8610685088735622,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_614",
        "exp_2261"
      ],
      "cosine_similarity": 0.8418818945865852,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8857142857142857,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.48125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.93,
      "score_detection": 0.68,
      "score_simulation": null,
      "score_embedding": 0.3948
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.925,
      "score_detection": 0.4857142857142857,
      "score_simulation": null,
      "score_embedding": 0.440625
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.875,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.440625
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.875,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.3948
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.9,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.48125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.94,
      "score_detection": 0.67,
      "score_simulation": null,
      "score_embedding": 0.3948
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.975,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.48125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.925,
      "score_detection": 0.725,
      "score_simulation": null,
      "score_embedding": 0.440625
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.10089090428965651,
      "z_score_fuzz": 1.86976175727972,
      "z_score_detection": 0.5228910548739643
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.5794666450669335,
      "z_score_fuzz": 1.8338335000328423,
      "z_score_detection": 0.6984084824723186
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.32578551931657246,
      "z_score_fuzz": 1.7881066271731787,
      "z_score_detection": 0.372447545503947
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.7639206359546759
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.6509251124794092
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.6115895511201844
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}