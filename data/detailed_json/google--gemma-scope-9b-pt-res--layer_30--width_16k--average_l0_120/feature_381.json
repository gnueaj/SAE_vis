{
  "feature_id": 381,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1142",
      "text": "Mathematical expressions and equations, often containing Greek letters, subscripts, and superscripts, typically in the context of quantum mechanics and theoretical physics.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_318",
      "text": "Mathematical and physical terminology involving specialized concepts such as renormalization, gauge invariance, wavefunctions, and quantum operators, often appearing in formal theoretical physics contexts with structured symbolic notation.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1965",
      "text": "The highlighted tokens are consistently domainâ€‘specific technical terms and LaTeX mathematical symbols that appear in scientific writing, especially physics and chemistry, often within equations or math mode. They are nouns or adjectives describing physical concepts and are usually part of LaTeX commands or mathematical expressions.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1142",
        "exp_318"
      ],
      "cosine_similarity": 0.8996402072974433,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1142",
        "exp_1965"
      ],
      "cosine_similarity": 0.8803583833772801,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_318",
        "exp_1965"
      ],
      "cosine_similarity": 0.8943164291940568,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.35,
      "score_detection": 0.34285714285714286,
      "score_simulation": null,
      "score_embedding": 0.498125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.40080000000000005
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6857142857142857,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5706249999999999
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5706249999999999
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.45714285714285713,
      "score_detection": 0.42857142857142855,
      "score_simulation": null,
      "score_embedding": 0.40080000000000005
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.498125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.56,
      "score_detection": 0.54,
      "score_simulation": null,
      "score_embedding": 0.40080000000000005
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.59,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.498125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5706249999999999
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.007473141124630096,
      "z_score_fuzz": -1.3213207272839196,
      "z_score_detection": -0.8979643113984263
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.5462514403860348,
      "z_score_fuzz": -0.8591526908808944,
      "z_score_detection": -0.41654508141436913
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.3938772487695579,
      "z_score_fuzz": -0.35942329462886097,
      "z_score_detection": -0.41320189231725774
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.7422527266023252
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.6073164042270994
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.12624931272552029
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}