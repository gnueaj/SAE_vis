{
  "feature_id": 115,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_918",
      "text": "Tokens that are part of proper nouns, titles, names, or specific identifiers, often denoting a unique entity, location, or concept.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_094",
      "text": "Fragments of proper nouns, technical terms, or identifiers often appear with partial or split spelling, frequently adjacent to punctuation or special characters, and are typically associated with scientific, academic, or formal text.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1742",
      "text": "The highlighted fragments are contiguous sequences of words or symbols that form a meaningful unit—idiomatic expressions, comparative adjectives, noun phrases, code tokens, or reference components—whose presence strongly influences the model’s output.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_918",
        "exp_094"
      ],
      "cosine_similarity": 0.8638701297414291,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_918",
        "exp_1742"
      ],
      "cosine_similarity": 0.8551473393267338,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_094",
        "exp_1742"
      ],
      "cosine_similarity": 0.8458858305771325,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.463125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.4084
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.48
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.48
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6571428571428571,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.4084
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.463125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.59,
      "score_detection": 0.52,
      "score_simulation": null,
      "score_embedding": 0.4084
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.7,
      "score_simulation": null,
      "score_embedding": 0.463125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.45,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.48
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.2012285017632036,
      "z_score_fuzz": -0.5553956068845597,
      "z_score_detection": 0.46438524567451234
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.5041788477902306,
      "z_score_fuzz": -0.3332936529947676,
      "z_score_detection": -0.07386819896043964
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.10781073859817716,
      "z_score_fuzz": -1.0698229265557715,
      "z_score_detection": -0.23768446471890342
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.09741295432441699
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.30378023324847925
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.4717727099576174
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}