{
  "feature_id": 225,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1015",
      "text": "Nouns representing negative events, actions, or states, often with serious consequences.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_191",
      "text": "Nouns denoting negative events or incidents, often related to harm, conflict, or legal/medical outcomes, frequently appearing in contexts involving consequences, damage, or formal proceedings.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1838",
      "text": "The highlighted words are event‑oriented nouns (often violent or negative) that serve as key terms in news‑style text.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1015",
        "exp_191"
      ],
      "cosine_similarity": 0.9490349441167347,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1015",
        "exp_1838"
      ],
      "cosine_similarity": 0.8962319010117737,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_191",
        "exp_1838"
      ],
      "cosine_similarity": 0.8855250187555165,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.6074999999999999
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.73,
      "score_detection": 0.48,
      "score_simulation": null,
      "score_embedding": 0.48960000000000004
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8285714285714286,
      "score_detection": 0.4666666666666667,
      "score_simulation": null,
      "score_embedding": 0.66875
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.825,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.66875
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.925,
      "score_detection": 0.675,
      "score_simulation": null,
      "score_embedding": 0.48960000000000004
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.75,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.6074999999999999
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.54,
      "score_simulation": null,
      "score_embedding": 0.48960000000000004
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.78,
      "score_detection": 0.58,
      "score_simulation": null,
      "score_embedding": 0.6074999999999999
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.825,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.66875
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.5980123608709121,
      "z_score_fuzz": 0.885000888194831,
      "z_score_detection": -0.1674774936795617
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.054666411108739536,
      "z_score_fuzz": 1.056476661418568,
      "z_score_detection": 0.04314341943846351
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.9370842419884161,
      "z_score_fuzz": 1.2246862294380434,
      "z_score_detection": -0.9592561115121374
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.4385119184620605
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.3483178899160973
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.40083811997144064
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}