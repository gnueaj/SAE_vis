{
  "feature_id": 398,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1154",
      "text": "Technical and scientific terms, often representing specific concepts, objects, or processes, in various fields such as neuroscience, medicine, and physics.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_330",
      "text": "Fragments of scientific and technical terms, often derived from compound words or abbreviations, where partial tokens (e.g., \\\"substantia\\\", \\\"temporal\\\", \\\"connectivity\\\", \\\"imaging\\\") are activated due to their role in specialized vocabulary, particularly in neuroscience, medicine, and physics.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1977",
      "text": "The highlighted fragments are the core lexical units that carry the main semantic content of each sentenceâ€”typically nouns, adjectives, or verb stems (sometimes in partial form). Their activation scores reflect how strongly each unit contributes to the overall meaning.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1154",
        "exp_330"
      ],
      "cosine_similarity": 0.9108515401958625,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1154",
        "exp_1977"
      ],
      "cosine_similarity": 0.8202178217507773,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_330",
        "exp_1977"
      ],
      "cosine_similarity": 0.8702156797401835,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.675,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.23125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.48,
      "score_simulation": null,
      "score_embedding": 0.31679999999999997
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.725,
      "score_detection": 0.3,
      "score_simulation": null,
      "score_embedding": 0.25875000000000004
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.25875000000000004
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7142857142857143,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.31679999999999997
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.675,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.23125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.31679999999999997
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.23125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.25875000000000004
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.4848577659937539,
      "z_score_fuzz": 0.24482466815954507,
      "z_score_detection": -0.5536158343959412
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -1.011264305918612,
      "z_score_fuzz": -0.0654648262453113,
      "z_score_detection": -0.5419146725560511
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.332621411206303,
      "z_score_fuzz": -0.6125541979591392,
      "z_score_detection": -0.9982599843117715
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.5978829774100499
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.5395479349066581
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.9811451978257381
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}