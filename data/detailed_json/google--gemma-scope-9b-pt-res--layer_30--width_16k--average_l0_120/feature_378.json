{
  "feature_id": 378,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1139",
      "text": "Tokens that are part of a larger unit, such as a word, phrase, or sentence, often with a specific grammatical or semantic function, and sometimes indicating a transition or connection between ideas.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_315",
      "text": "Fragments of words, abbreviations, or technical terms that appear in isolation or are split across tokens, often representing parts of compound words, identifiers, or symbolic notation.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1962",
      "text": "Important tokens are contiguous character sequences—often partial words, full words, or short phrases—selected for activation, sometimes including punctuation or numbers, reflecting the model’s focus on semantically or syntactically salient fragments.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1139",
        "exp_315"
      ],
      "cosine_similarity": 0.8632367346950113,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1139",
        "exp_1962"
      ],
      "cosine_similarity": 0.8791060811953493,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_315",
        "exp_1962"
      ],
      "cosine_similarity": 0.8712774989464559,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.3,
      "score_detection": 0.25,
      "score_simulation": null,
      "score_embedding": 0.9232
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.44,
      "score_detection": 0.68,
      "score_simulation": -0.008383939970686309,
      "score_embedding": 0.972
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.475,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5428571428571428,
      "score_detection": 0.7,
      "score_simulation": 0.036292201356103386,
      "score_embedding": 0.972
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.275,
      "score_detection": 0.3,
      "score_simulation": null,
      "score_embedding": 0.9232
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.57,
      "score_detection": 0.84,
      "score_simulation": -0.04588098787021144,
      "score_embedding": 0.972
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.18,
      "score_detection": 0.17,
      "score_simulation": -0.03281530760442765,
      "score_embedding": 0.9232
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}