{
  "feature_id": 150,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_949",
      "text": "Tokens that are part of proper nouns, technical terms, or descriptive words, often related to technology, architecture, or design.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_125",
      "text": "Commonly activated tokens include suffixes like \\\"er\\\", \\\"ing\\\", \\\"ed\\\", and \\\"s\\\", as well as words related to technical specifications, architectural terms, and descriptive adjectives, often appearing in contexts involving design, technology, or physical spaces.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1773",
      "text": "The highlighted tokens are the semantic core of each sentenceâ€”primarily nouns and adjectives (often part of product or brand names or descriptive phrases) that carry the main meaning and define the subject, object, or attribute.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_949",
        "exp_125"
      ],
      "cosine_similarity": 0.9290857305716327,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_949",
        "exp_1773"
      ],
      "cosine_similarity": 0.8796424453304842,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_125",
        "exp_1773"
      ],
      "cosine_similarity": 0.8554721196516397,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.5918749999999999
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.56,
      "score_detection": 0.56,
      "score_simulation": null,
      "score_embedding": 0.5676
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.625,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.40187500000000004
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.675,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.40187500000000004
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.5676
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.5918749999999999
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.5676
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.64,
      "score_simulation": null,
      "score_embedding": 0.5918749999999999
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.775,
      "score_detection": 0.7,
      "score_simulation": null,
      "score_embedding": 0.40187500000000004
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.511514432014406,
      "z_score_fuzz": -0.1552854693625081,
      "z_score_detection": 0.32397130359582965
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.3771312497429386,
      "z_score_fuzz": -0.3038978061564124,
      "z_score_detection": -0.03876471344076877
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.5403003828807073,
      "z_score_fuzz": 0.3019832592341254,
      "z_score_detection": 0.2888678180761588
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.22673342208257585
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.011489576715252485
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.016850231476525646
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}