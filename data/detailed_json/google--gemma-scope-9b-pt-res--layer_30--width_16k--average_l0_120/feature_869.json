{
  "feature_id": 869,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1535",
      "text": "Special tokens or keywords in programming languages, often denoting specific data types, functions, or syntax elements.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_711",
      "text": "Special tokens or keywords in programming languages, often denoting specific data types, functions, or syntax elements.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2358",
      "text": "The highlighted tokens are consistently code‑related identifiers or fragments—variable names, function or class names, keywords, file paths, or other syntactic elements—drawn from source code, comments, strings, or documentation. They appear in a variety of contexts (e.g., code bodies, comments, file names, XML/HTML tags) and are usually contiguous character sequences that form a meaningful unit within programming syntax.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_distance_pairs": [
    {
      "pair": [
        "exp_1535",
        "exp_711"
      ],
      "cosine_distance": 1.1102230246251565e-16,
      "euclidean_distance": null
    },
    {
      "pair": [
        "exp_1535",
        "exp_2358"
      ],
      "cosine_distance": 0.10020005993232095,
      "euclidean_distance": null
    },
    {
      "pair": [
        "exp_711",
        "exp_2358"
      ],
      "cosine_distance": 0.10020005993232095,
      "euclidean_distance": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.37142857142857144,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.62,
      "score_simulation": -0.02069935052202545,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.44,
      "score_detection": 0.7111111111111111,
      "score_simulation": 0.011727992902451518,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.4,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.61,
      "score_detection": 0.54,
      "score_simulation": -0.013430888722118617,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.4,
      "score_simulation": 0.03341962508490847,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}