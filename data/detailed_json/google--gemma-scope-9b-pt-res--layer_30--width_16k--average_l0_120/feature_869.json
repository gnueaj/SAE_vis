{
  "feature_id": 869,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1535",
      "text": "Special tokens or keywords in programming languages, often denoting specific data types, functions, or syntax elements.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_711",
      "text": "Patterns involving identifiers, file extensions, or technical terms enclosed in delimiters, often representing code elements, configuration keys, or syntax constructs in programming or markup languages.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2358",
      "text": "The highlighted tokens are consistently code‑related identifiers or fragments—variable names, function or class names, keywords, file paths, or other syntactic elements—drawn from source code, comments, strings, or documentation. They appear in a variety of contexts (e.g., code bodies, comments, file names, XML/HTML tags) and are usually contiguous character sequences that form a meaningful unit within programming syntax.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1535",
        "exp_711"
      ],
      "cosine_similarity": 0.892435574732508,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1535",
        "exp_2358"
      ],
      "cosine_similarity": 0.899799940067679,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_711",
        "exp_2358"
      ],
      "cosine_similarity": 0.9051404449433446,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.37142857142857144,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.561875
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.62,
      "score_simulation": null,
      "score_embedding": 0.5796
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5428571428571428,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.593125
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.593125
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.42857142857142855,
      "score_detection": 0.5714285714285714,
      "score_simulation": null,
      "score_embedding": 0.5796
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.4,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.561875
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.61,
      "score_detection": 0.54,
      "score_simulation": null,
      "score_embedding": 0.5796
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.561875
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.593125
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.34543840860991487,
      "z_score_fuzz": -1.4780985770884785,
      "z_score_detection": -0.9397541751123203
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.44356165910473533,
      "z_score_fuzz": -0.6958424306678122,
      "z_score_detection": 0.12839474141480603
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.518434266322927,
      "z_score_fuzz": -0.8575195882787642,
      "z_score_detection": -0.6472251291150637
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.6908047811969613
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.04129534338275693
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.32877015035696694
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}