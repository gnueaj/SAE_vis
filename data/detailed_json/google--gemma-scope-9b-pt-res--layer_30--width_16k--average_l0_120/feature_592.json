{
  "feature_id": 592,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1311",
      "text": "Nouns, noun phrases, or words that are part of a compound word, often representing objects, concepts, or actions, and sometimes indicating a relationship or a characteristic.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_487",
      "text": "Compound nouns or multi-word terms where the first part is a modifier and the second part is a core noun, often representing a specific concept, location, or technical term, with the second word typically carrying higher activation importance.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2134",
      "text": "The highlighted tokens are usually the core nouns or noun phrases that carry the main semantic content of the surrounding phrase, often representing objects, concepts, or entities, and occasionally key adjectives or prepositions that form idiomatic expressions.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1311",
        "exp_487"
      ],
      "cosine_similarity": 0.913421705050817,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1311",
        "exp_2134"
      ],
      "cosine_similarity": 0.8810605658794187,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_487",
        "exp_2134"
      ],
      "cosine_similarity": 0.8791193340440198,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.23562500000000003
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.58,
      "score_detection": 0.44,
      "score_simulation": null,
      "score_embedding": 0.18840000000000004
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.273125
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.273125
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.75,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.18840000000000004
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.23562500000000003
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.46,
      "score_simulation": null,
      "score_embedding": 0.18840000000000004
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.73,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.23562500000000003
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.273125
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.460638345913932,
      "z_score_fuzz": 0.42773215959819827,
      "z_score_detection": -0.050465875280659316
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -1.7220696860898361,
      "z_score_fuzz": 0.3134149774490407,
      "z_score_detection": -0.6472251291150637
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.2530433166583175,
      "z_score_fuzz": 0.5877762146070201,
      "z_score_detection": -0.23768446471890342
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.36112402053213105
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.6852932792519532
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.30098385559006696
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}