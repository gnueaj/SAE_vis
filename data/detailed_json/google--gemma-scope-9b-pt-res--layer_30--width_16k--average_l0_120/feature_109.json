{
  "feature_id": 109,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_915",
      "text": "Prepositions and nouns often function as important tokens, with prepositions like \\\"from\\\", \\\"of\\\", and \\\"in\\\" frequently appearing, while nouns tend to represent objects, concepts, or actions, such as \\\"paper\\\", \\\"speech\\\", \\\"risk\\\", and \\\"experience\\\".",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_091",
      "text": "Common noun phrases or key terms that denote specific concepts, locations, or abstract ideas, often appearing in academic, technical, or descriptive contexts, with high activation values on content-bearing words.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1739",
      "text": "The highlighted words are typically function words or small content words that serve as the glue in key collocations or idiomatic expressions, linking the main lexical items and carrying essential semantic weight.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_915",
        "exp_091"
      ],
      "cosine_similarity": 0.8631957048362513,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_915",
        "exp_1739"
      ],
      "cosine_similarity": 0.8479588691055987,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_091",
        "exp_1739"
      ],
      "cosine_similarity": 0.8561025362766942,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.41,
      "score_detection": 0.39,
      "score_simulation": 0.06189263706930813,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.4888888888888889,
      "score_simulation": 0.1080399041030941,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.35,
      "score_detection": 0.325,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.52,
      "score_detection": 0.31,
      "score_simulation": 0.1503374774525326,
      "score_embedding": 0.8112
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.38,
      "score_detection": 0.21,
      "score_simulation": -0.014459098847555729,
      "score_embedding": 0.6275999999999998
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.375,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}