{
  "feature_id": 432,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1177",
      "text": "Common nouns, adjectives, and verbs that are often used in formal or technical writing, including words related to sports, science, and law, as well as words that indicate time, place, and quantity.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_353",
      "text": "Nouns and noun phrases denoting locations, events, or abstract concepts, often appearing in contexts involving categories, measurements, or descriptive attributes.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2000",
      "text": "The tokens are various words: \\\"statements\\\", \\\"athy\\\", \\\"Es\\\", \\\"patient\\\", \\\"year\\\", \\\"winning\\\", \\\"first\\\", \\\"6\\\", \\\"3\\\", \\\"in\\\", \\\"season\\\", \\\"th\\\", \\\"second\\\", \\\"six\\\", \\\"categories\\\", \\\"aged\\\", \\\"City\\\", \\\"Swansea\\\", \\\"was\\\", \\\"lower\\\", \\\"Bowl\\\", \\\"specimens\\\", \\\"supporting\\\", \\\"â€™\\\", \\\"season\\\", \\\"them\\\", \\\"everyone\\\", \\\"matches\\\", \\\"race\\\", \\\"activation\\\", \\\"English\\\", \\\"activity\\\", \\\"levels\\\", \\\"reaction\\\", \\\"since\\\", \\\"festival\\\", \\\"and\\\", \\\"Clinton\\\", \\\"added\\\", \\\"fire\\\", \\\"participants\\\", \\\"won\\\", \\\"service\\\", \\\"every\\\", \\\"song\\\", \\\"hit\\\", \\\"Challenges\\\", \\\"also\\\", \\\"proceeded\\\", \\\"fans\\\", \\\"crimes\\\", \\\"employed\\\".",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1177",
        "exp_353"
      ],
      "cosine_similarity": 0.875455734978182,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1177",
        "exp_2000"
      ],
      "cosine_similarity": 0.8344566214746709,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_353",
        "exp_2000"
      ],
      "cosine_similarity": 0.8119703225274275,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.675,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6768750000000001
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.49,
      "score_detection": 0.51,
      "score_simulation": null,
      "score_embedding": 0.6487999999999999
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.42857142857142855,
      "score_simulation": null,
      "score_embedding": 0.49125
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.49125
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.675,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6487999999999999
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.6768750000000001
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.76,
      "score_detection": 0.47,
      "score_simulation": null,
      "score_embedding": 0.6487999999999999
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.48,
      "score_simulation": null,
      "score_embedding": 0.6768750000000001
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.49125
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.9820631649938002,
      "z_score_fuzz": -0.040968287213348956,
      "z_score_detection": -0.5770181580757219
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.8266436864244291,
      "z_score_fuzz": -0.040968287213348956,
      "z_score_detection": -0.46000653967681876
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.045532229821492576,
      "z_score_fuzz": -0.49823701580998164,
      "z_score_detection": -0.5218555379733814
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.12135890656824311
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.10855628651142045
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.3552082612016185
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}