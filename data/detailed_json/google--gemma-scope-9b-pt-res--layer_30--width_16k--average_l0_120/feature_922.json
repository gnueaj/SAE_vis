{
  "feature_id": 922,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1580",
      "text": "Prepositions and articles, often preceding nouns, and sometimes chemical or biological terms, or units of measurement.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_756",
      "text": "The token \\\"of\\\" frequently appears in scientific text when describing relationships between components, such as in measurements, biological processes, or structural compositions, often linking a general category to a specific instance or property.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2403",
      "text": "The highlighted fragments are usually short prepositions, articles, or parts of chemical or biological terms and units, forming contiguous noun phrases or measurement expressions in scientific text.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1580",
        "exp_756"
      ],
      "cosine_similarity": 0.8796699783980814,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1580",
        "exp_2403"
      ],
      "cosine_similarity": 0.915512277020168,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_756",
        "exp_2403"
      ],
      "cosine_similarity": 0.8837305806756458,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5714285714285714,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.61625
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.56,
      "score_detection": 0.51,
      "score_simulation": null,
      "score_embedding": 0.6479999999999999
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.575,
      "score_detection": 0.52,
      "score_simulation": null,
      "score_embedding": 0.6575
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.525,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.6575
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6479999999999999
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.61625
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.61,
      "score_detection": 0.56,
      "score_simulation": null,
      "score_embedding": 0.6479999999999999
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.61625
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.625,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.6575
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.6464512010305558,
      "z_score_fuzz": -0.6207197109697942,
      "z_score_detection": -0.2961902739183554
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.8222149924669758,
      "z_score_fuzz": -0.509668734024897,
      "z_score_detection": -0.24938562655879395
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.8748057332117318,
      "z_score_fuzz": -0.49823701580998087,
      "z_score_detection": -0.015362389760988452
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.09015292795253127
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.02105354396109496
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.1204021092135875
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}