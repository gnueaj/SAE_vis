{
  "feature_id": 460,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1203",
      "text": "Prefixes or suffixes of words, often indicating a relationship or a characteristic, and sometimes part of proper nouns or abbreviations.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_379",
      "text": "Partial or truncated proper nouns, abbreviations, or technical terms often appear with lowercase or fragmented spelling, typically preceding or following a contextually significant word or symbol.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2026",
      "text": "The model highlights subword fragments that are part of larger identifiers or words, often at the start or end, indicating sensitivity to morphological or code token boundaries.\\\" Also mention that many tokens are prefixes like \\\"NS\\\", \\\"ns\\\", \\\"Ins\\\", \\\"ens\\\", \\\"ensuring\\\", \\\"ensure\\\", \\\"insured\\\", \\\"insurance\\\", \\\"inscribed\\\", \\\"insulin\\\", \\\"ins\\\", \\\"NSLog\\\", \\\"namespace\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", ",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1203",
        "exp_379"
      ],
      "cosine_similarity": 0.8840891272146119,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1203",
        "exp_2026"
      ],
      "cosine_similarity": 0.8555328937291765,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_379",
        "exp_2026"
      ],
      "cosine_similarity": 0.8612367574172628,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.5692
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.74,
      "score_detection": 0.68,
      "score_simulation": 0.11249508006047454,
      "score_embedding": 0.6952
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.7142857142857143,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.675,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.675,
      "score_detection": 0.6857142857142857,
      "score_simulation": 0.19923327801065396,
      "score_embedding": 0.6952
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.8,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.5692
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.78,
      "score_detection": 0.72,
      "score_simulation": -0.0023538957471622695,
      "score_embedding": 0.6952
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7684210526315789,
      "score_detection": 0.6736842105263158,
      "score_simulation": 0.15129741346002612,
      "score_embedding": 0.5692
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.8,
      "score_detection": 0.775,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}