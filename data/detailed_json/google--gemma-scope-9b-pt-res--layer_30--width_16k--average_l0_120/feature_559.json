{
  "feature_id": 559,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1283",
      "text": "French words or phrases, often used in formal or literary contexts, and sometimes used to add a touch of elegance or sophistication to the text.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_459",
      "text": "Fragments of words or phrases that are part of compound terms, proper nouns, or technical expressions, often appearing in incomplete or partially tokenized form, with high activation on morphological or orthographic boundaries.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2106",
      "text": "The highlighted fragments consistently capture the core lexical content of a phrase or word—whether a noun phrase, idiomatic expression, or a morphological fragment—providing the main semantic load of the surrounding text.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1283",
        "exp_459"
      ],
      "cosine_similarity": 0.8170243261408513,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1283",
        "exp_2106"
      ],
      "cosine_similarity": 0.8165735932973658,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_459",
        "exp_2106"
      ],
      "cosine_similarity": 0.8608466477769348,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.45714285714285713,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.49875
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.73,
      "score_detection": 0.74,
      "score_simulation": null,
      "score_embedding": 0.7043999999999999
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7666666666666667,
      "score_detection": 0.4857142857142857,
      "score_simulation": null,
      "score_embedding": 0.628125
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.628125
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.825,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.7043999999999999
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.49875
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.79,
      "score_detection": 0.74,
      "score_simulation": null,
      "score_embedding": 0.7043999999999999
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.34,
      "score_detection": 0.43,
      "score_simulation": null,
      "score_embedding": 0.49875
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.575,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.628125
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.0040132239703696195,
      "z_score_fuzz": -1.6479412477100845,
      "z_score_detection": -0.40150073047736795
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 1.13443791646742,
      "z_score_fuzz": 0.9192960428395777,
      "z_score_detection": 1.4121793547056265
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.7121896269615008,
      "z_score_fuzz": 0.05429603124428238,
      "z_score_detection": -0.4466337832883727
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.6844850673859407
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 1.1553044380042081
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.10661729163913682
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}