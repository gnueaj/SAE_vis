{
  "feature_id": 853,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1525",
      "text": "Prices, numerical values, and units of measurement, often in the context of commerce, travel, or product information.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_701",
      "text": "Common patterns include numerical values, punctuation marks, and specific lexical items related to pricing, time, or technical formatting, often appearing in contexts involving measurements, financial details, or structured data.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2348",
      "text": "The highlighted tokens are the core lexical items that carry the main semantic content of each sentence, often forming contiguous phrases that represent key concepts, product terms, or numeric values, and they are the ones the model considers most informative for the text's meaning.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1525",
        "exp_701"
      ],
      "cosine_similarity": 0.9030920234391391,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1525",
        "exp_2348"
      ],
      "cosine_similarity": 0.813031749993505,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_701",
        "exp_2348"
      ],
      "cosine_similarity": 0.8383436167452281,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.725,
      "score_detection": 0.7,
      "score_simulation": null,
      "score_embedding": 0.468125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.66,
      "score_detection": 0.76,
      "score_simulation": null,
      "score_embedding": 0.3748
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5714285714285714,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.10250000000000001
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.10250000000000001
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.3748
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.468125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.69,
      "score_simulation": null,
      "score_embedding": 0.3748
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.625,
      "score_detection": 0.825,
      "score_simulation": null,
      "score_embedding": 0.468125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.10250000000000001
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.1735491645291216,
      "z_score_fuzz": 0.24482466815954507,
      "z_score_detection": 1.5174898112646382
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.6901839940032611,
      "z_score_fuzz": 0.03905374029106121,
      "z_score_detection": 0.9324317192701249
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -2.197600699771364,
      "z_score_fuzz": 0.17950056407431214,
      "z_score_detection": 0.7569142916717698
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.5295884382983539
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.093767155185975
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.42039528134176063
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}