{
  "feature_id": 853,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1525",
      "text": "Prices, numerical values, and units of measurement, often in the context of commerce, travel, or product information.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_701",
      "text": "Prices, numerical values, and units of measurement, often in the context of commerce, travel, or product information.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2348",
      "text": "The highlighted tokens are the core lexical items that carry the main semantic content of each sentence, often forming contiguous phrases that represent key concepts, product terms, or numeric values, and they are the ones the model considers most informative for the text's meaning.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1525",
        "exp_701"
      ],
      "cosine_similarity": 1.0,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1525",
        "exp_2348"
      ],
      "cosine_similarity": 0.813031749993505,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_701",
        "exp_2348"
      ],
      "cosine_similarity": 0.813031749993505,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.725,
      "score_detection": 0.7,
      "score_simulation": null,
      "score_embedding": 0.468125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.66,
      "score_detection": 0.76,
      "score_simulation": null,
      "score_embedding": 0.3748
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5714285714285714,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.10250000000000001
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.10250000000000001
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.3748
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.468125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.69,
      "score_simulation": null,
      "score_embedding": 0.3748
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.625,
      "score_detection": 0.825,
      "score_simulation": null,
      "score_embedding": 0.468125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.10250000000000001
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}