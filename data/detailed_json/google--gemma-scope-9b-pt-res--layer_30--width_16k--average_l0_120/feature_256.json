{
  "feature_id": 256,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1038",
      "text": "Proper nouns, often representing names of places, organizations, or specific entities, and sometimes including words that are part of a title or a formal name.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_214",
      "text": "Proper nouns or compound terms often consisting of two or more capitalized words, frequently representing geographical locations, organizations, technical terms, or branded entities, with high activation on the constituent parts, especially when forming a recognized name or label.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1861",
      "text": "The highlighted tokens are the semantic anchors of the text: they are either nouns or proper nouns that form part of named entities or idiomatic expressions, or morphological markers (e.g., comparative suffix “er”) that signal key relationships. They tend to be capitalized or appear in multi‑word phrases that convey a specific meaning.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1038",
        "exp_214"
      ],
      "cosine_similarity": 0.9081514668219709,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1038",
        "exp_1861"
      ],
      "cosine_similarity": 0.8668311045068005,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_214",
        "exp_1861"
      ],
      "cosine_similarity": 0.8832079499104958,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.75,
      "score_simulation": null,
      "score_embedding": 0.6112500000000001
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.75,
      "score_detection": 0.73,
      "score_simulation": null,
      "score_embedding": 0.6252
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.34249999999999997
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.34249999999999997
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.6252
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.6112500000000001
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.74,
      "score_detection": 0.76,
      "score_simulation": null,
      "score_embedding": 0.6252
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.74,
      "score_detection": 0.75,
      "score_simulation": null,
      "score_embedding": 0.6112500000000001
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.34249999999999997
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.6187718637964744,
      "z_score_fuzz": 0.6792299603263464,
      "z_score_detection": 1.1079491468684786
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.6959972146795625,
      "z_score_fuzz": 0.564912778177188,
      "z_score_detection": 1.435581678385406
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.8689925125354308,
      "z_score_fuzz": 0.18766607708496624,
      "z_score_detection": -0.2961902739183554
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.8019836569970998
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.8988305570807188
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.32583890312293995
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}