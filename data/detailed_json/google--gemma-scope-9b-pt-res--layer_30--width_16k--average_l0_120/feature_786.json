{
  "feature_id": 786,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1475",
      "text": "Organizations, institutions, and concepts related to environmental conservation, wildlife, and natural resources, often denoted by proper nouns or specific terminology.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_651",
      "text": "Common patterns include compound nouns and proper nouns related to environmental, conservation, or governmental organizations, often involving terms like \\\"environmental,\\\" \\\"wildlife,\\\" \\\"conservation,\\\" \\\"protection,\\\" \\\"natural,\\\" \\\"climate,\\\" \\\"oceanic,\\\" \\\"forest,\\\" \\\"biodiversity,\\\" and institutional names such as \\\"National Trust,\\\" \\\"Environmental Protection Agency,\\\" or \\\"UN,\\\" frequently appearing in contexts related to ecological or scientific topics.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2298",
      "text": "The model consistently flags domainâ€‘specific nouns and adjectives that denote environmental entities, organizations, policies, and natural features, treating these terms as key contextual anchors.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1475",
        "exp_651"
      ],
      "cosine_similarity": 0.9235945095187125,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1475",
        "exp_2298"
      ],
      "cosine_similarity": 0.8538312407044671,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_651",
        "exp_2298"
      ],
      "cosine_similarity": 0.8668041221614479,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.61125
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.78,
      "score_detection": 0.68,
      "score_simulation": null,
      "score_embedding": 0.6852
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7714285714285715,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.36124999999999996
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.725,
      "score_detection": 0.775,
      "score_simulation": null,
      "score_embedding": 0.36124999999999996
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.675,
      "score_simulation": null,
      "score_embedding": 0.6852
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.75,
      "score_detection": 0.75,
      "score_simulation": null,
      "score_embedding": 0.61125
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.78,
      "score_detection": 0.63,
      "score_simulation": null,
      "score_embedding": 0.6852
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.675,
      "score_simulation": null,
      "score_embedding": 0.61125
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.8,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.36124999999999996
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.6187718637964738,
      "z_score_fuzz": 0.35914185030870416,
      "z_score_detection": 0.8739259100706722
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 1.0281492614885461,
      "z_score_fuzz": 0.6106396510368515,
      "z_score_detection": 0.7218108061520989
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.7651949979076235,
      "z_score_fuzz": 0.808245065894682,
      "z_score_detection": 0.3473736272756108
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.6172798747252833
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.786866572892499
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.13014123175422312
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}