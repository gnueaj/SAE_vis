{
  "feature_id": 674,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1381",
      "text": "Tokens that are part of a code or programming syntax, often including symbols, keywords, and variable names.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_557",
      "text": "Fragments of structured or formatted text, including code, mathematical expressions, markup, citations, and technical notation, often containing isolated tokens or partial words that are part of larger syntactic or semantic constructs.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2204",
      "text": "The highlighted fragments are arbitrary tokens inside delimiters, ranging from words and numbers to punctuation and code, and each token is treated as important regardless of its semantic content.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1381",
        "exp_557"
      ],
      "cosine_similarity": 0.898146921264582,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1381",
        "exp_2204"
      ],
      "cosine_similarity": 0.8763206855573272,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_557",
        "exp_2204"
      ],
      "cosine_similarity": 0.88575598975492,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.4,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.520625
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.25,
      "score_detection": 0.22,
      "score_simulation": null,
      "score_embedding": 0.33359999999999995
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5325
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5325
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.35,
      "score_detection": 0.225,
      "score_simulation": null,
      "score_embedding": 0.33359999999999995
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.4,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.520625
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.21052631578947367,
      "score_detection": 0.16,
      "score_simulation": null,
      "score_embedding": 0.33359999999999995
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.38,
      "score_detection": 0.31,
      "score_simulation": null,
      "score_embedding": 0.520625
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.35,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.5325
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}