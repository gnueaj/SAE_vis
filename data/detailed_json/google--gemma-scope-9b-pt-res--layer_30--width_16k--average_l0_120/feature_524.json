{
  "feature_id": 524,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1252",
      "text": "Various tokens that appear to be significant in different contexts, including units of measurement, adjectives, nouns, and punctuation marks, often indicating a specific attribute, quantity, or relationship.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_428",
      "text": "Commonly activated tokens include comparative suffixes, punctuation marks, proper nouns, and descriptive adjectives, often appearing in contexts involving measurements, time, location, or qualitative attributes.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2075",
      "text": "The activations consistently target content words that serve as key descriptors or modifiers in phrases—often nouns or adjectives—and punctuation that signals clause boundaries, indicating the model’s focus on semantically salient lexical items and structural markers.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1252",
        "exp_428"
      ],
      "cosine_similarity": 0.9317185151064239,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1252",
        "exp_2075"
      ],
      "cosine_similarity": 0.8761104408986466,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_428",
        "exp_2075"
      ],
      "cosine_similarity": 0.8936069202215278,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.41812499999999997
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.41,
      "score_detection": 0.48,
      "score_simulation": null,
      "score_embedding": 0.4364
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.47937500000000005
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.475,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.47937500000000005
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.4364
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.4,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": 0.41812499999999997
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.42,
      "score_detection": 0.18,
      "score_simulation": null,
      "score_embedding": 0.4364
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.29,
      "score_detection": 0.2,
      "score_simulation": null,
      "score_embedding": 0.41812499999999997
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.725,
      "score_simulation": null,
      "score_embedding": 0.47937500000000005
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.4503425368699413,
      "z_score_fuzz": -1.3784793183584978,
      "z_score_detection": -1.5248122671068345
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.3491745592793716,
      "z_score_fuzz": -1.40134275478833,
      "z_score_detection": -1.267386706629248
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.11127065575243703,
      "z_score_fuzz": -0.2696026515116657,
      "z_score_detection": -0.003661227921098684
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -1.1178780407784246
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -1.0059680068989831
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.12817817839506715
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}