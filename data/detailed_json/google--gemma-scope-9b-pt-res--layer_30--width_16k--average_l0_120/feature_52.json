{
  "feature_id": 52,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_868",
      "text": "Punctuation marks and conjunctions, often used to connect clauses or items in a list, and sometimes preceding or following a quotation.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_044",
      "text": "Common conjunctions like \\\"and\\\", possessive pronouns like \\\"his\\\", and function words like \\\"in\\\", \\\"the\\\", \\\"to\\\", \\\"it\\\", \\\"you\\\", \\\"I\\\", \\\"m\\\", \\\"s\\\", \\\"er\\\", and punctuation tokens such as commas, periods, and parentheses are frequently activated in diverse syntactic and semantic contexts, often serving grammatical or structural roles in sentences.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1692",
      "text": "The model highlights short function words that serve as syntactic glue—conjunctions, prepositions, articles, and occasionally punctuation—often in brief sequences that link clauses or items.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_868",
        "exp_044"
      ],
      "cosine_similarity": 0.8849676747525783,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_868",
        "exp_1692"
      ],
      "cosine_similarity": 0.872638247495244,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_044",
        "exp_1692"
      ],
      "cosine_similarity": 0.8821767664244557,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.316875
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.52,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.3596
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.8285714285714286,
      "score_simulation": null,
      "score_embedding": 0.29499999999999993
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.29499999999999993
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7666666666666667,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.3596
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.35,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.316875
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.68,
      "score_detection": 0.74,
      "score_simulation": null,
      "score_embedding": 0.3596
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.71,
      "score_detection": 0.73,
      "score_simulation": null,
      "score_embedding": 0.316875
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.29499999999999993
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.0108491158601005,
      "z_score_fuzz": -0.5325321704547291,
      "z_score_detection": 0.3590747891155005
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.7743291791948704,
      "z_score_fuzz": 0.05429603124428238,
      "z_score_detection": 0.9207305574302344
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.1319462162592095,
      "z_score_fuzz": -0.21244406043708688,
      "z_score_detection": 1.0578013104118067
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.3947688323997764
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.06689913649321544
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.09552965542816327
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}