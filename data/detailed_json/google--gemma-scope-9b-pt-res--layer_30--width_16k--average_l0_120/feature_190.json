{
  "feature_id": 190,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_985",
      "text": "Punctuation marks, mathematical symbols, and special characters, often used to denote specific formatting, mathematical operations, or to set off text.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_161",
      "text": "Common patterns include the use of delimiters, punctuation, and special symbols in technical or structured text, often surrounding identifiers, mathematical expressions, or markup elements, with frequent activation of tokens related to formatting, structure, or syntax.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1809",
      "text": "The highlighted fragments are the core content units that carry the main meaning of a phrase or code snippetâ€”typically contiguous words or symbols that form a coherent idiom, noun phrase, or functional element, while function words and extraneous tokens are omitted.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_985",
        "exp_161"
      ],
      "cosine_similarity": 0.8958924936996546,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_985",
        "exp_1809"
      ],
      "cosine_similarity": 0.7988242969016995,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_161",
        "exp_1809"
      ],
      "cosine_similarity": 0.8361668336748717,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.525,
      "score_detection": 0.325,
      "score_simulation": null,
      "score_embedding": 0.51625
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.35,
      "score_detection": 0.39,
      "score_simulation": null,
      "score_embedding": 0.5544
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.45714285714285713,
      "score_simulation": null,
      "score_embedding": 0.62
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.35,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.62
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5142857142857142,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.5544
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.3,
      "score_detection": 0.325,
      "score_simulation": null,
      "score_embedding": 0.51625
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.3,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": 0.5544
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.36,
      "score_detection": 0.44,
      "score_simulation": null,
      "score_embedding": 0.51625
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": 0.62
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.09286445634891696,
      "z_score_fuzz": -1.7328625830208877,
      "z_score_detection": -1.3726971631882605
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.3040577994449623,
      "z_score_fuzz": -1.7802225584826823,
      "z_score_detection": -1.021662307991552
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.6672107039561174,
      "z_score_fuzz": -1.1269815176303504,
      "z_score_detection": -0.9230382296267629
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -1.0042317632867437
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.8326090223430906
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.4609363477669986
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}