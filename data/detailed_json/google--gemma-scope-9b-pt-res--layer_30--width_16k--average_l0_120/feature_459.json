{
  "feature_id": 459,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1202",
      "text": "Various symbols, punctuation, and short words or phrases that serve as delimiters, operators, or conjunctions in different contexts, including programming, mathematics, and formal writing.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_378",
      "text": "Empty or whitespace-filled tokens, punctuation, and special symbols often serve as structural or syntactic markers in text, particularly in code, mathematical notation, or formatted documents, with activations indicating their role in parsing or formatting.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2025",
      "text": "The highlighted words are the core lexical elements that carry the main semantic content of a phraseâ€”typically nouns, adjectives, or key verbs, and occasionally punctuation that signals structure.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1202",
        "exp_378"
      ],
      "cosine_similarity": 0.876873105352017,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1202",
        "exp_2025"
      ],
      "cosine_similarity": 0.8403479666072395,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_378",
        "exp_2025"
      ],
      "cosine_similarity": 0.8462707756615286,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.45,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.514375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.4,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.6504000000000001
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.625,
      "score_detection": 0.7,
      "score_simulation": null,
      "score_embedding": 0.525625
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.35,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.525625
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.525,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6504000000000001
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.475,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.514375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.39,
      "score_detection": 0.34,
      "score_simulation": null,
      "score_embedding": 0.6504000000000001
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.37,
      "score_detection": 0.31,
      "score_simulation": null,
      "score_embedding": 0.514375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.575,
      "score_detection": 0.775,
      "score_simulation": null,
      "score_embedding": 0.525625
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.08248470488613646,
      "z_score_fuzz": -1.4813647822927405,
      "z_score_detection": -0.857846042233088
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.8355010743393362,
      "z_score_fuzz": -1.4356379094330773,
      "z_score_detection": -0.811041394873527
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.14476321366282074,
      "z_score_fuzz": -0.8983471533320347,
      "z_score_detection": 0.7569142916717698
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.7522420398798974
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.4703927433224227
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.001110117334185275
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}