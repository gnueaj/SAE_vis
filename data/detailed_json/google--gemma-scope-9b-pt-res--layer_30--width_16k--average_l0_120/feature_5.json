{
  "feature_id": 5,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_830",
      "text": "Punctuation marks, particularly commas, periods, and occasionally other symbols, often used to separate items in lists, set off clauses, or indicate the end of a sentence, and sometimes linking clauses or phrases.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_006",
      "text": "Common function words and punctuation marks (such as \\\"is\\\", \\\"was\\\", \\\",\\\", \\\".\\\", \\\"er\\\", \\\"especially\\\") that serve grammatical or syntactic roles in sentences, often appearing in contexts involving description, evaluation, or structural formatting.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1654",
      "text": "The highlighted tokens are mainly short, highâ€‘frequency function words or components of common idiomatic collocations that carry grammatical or semantic weight in the sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_830",
        "exp_006"
      ],
      "cosine_similarity": 0.8777909279931312,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_830",
        "exp_1654"
      ],
      "cosine_similarity": 0.82743984869048,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_006",
        "exp_1654"
      ],
      "cosine_similarity": 0.9032562479666448,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.475,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.6362500000000001
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.54,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.5496
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.4,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.6531250000000001
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.6531250000000001
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.5496
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.75,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6362500000000001
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.74,
      "score_detection": 0.47,
      "score_simulation": null,
      "score_embedding": 0.5496
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.74,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.6362500000000001
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.6531250000000001
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}