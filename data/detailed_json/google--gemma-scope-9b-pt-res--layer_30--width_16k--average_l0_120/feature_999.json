{
  "feature_id": 999,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1648",
      "text": "Articles, prepositions, and conjunctions, often used to connect words or phrases, or to indicate possession, location, or relationship.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_824",
      "text": "Common function words and determiners (like \\\"the\\\", \\\"a\\\", \\\"of\\\", \\\"in\\\", \\\"than\\\", \\\"more\\\") frequently appear in context with specific nouns, adjectives, or phrases, often forming grammatical or semantic dependencies, particularly in descriptive, comparative, or abstract constructions.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2471",
      "text": "The important tokens are almost always short, highâ€‘frequency function words or punctuation, often grouped into contiguous phrases that carry grammatical or semantic weight.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1648",
        "exp_824"
      ],
      "cosine_similarity": 0.8876075862612005,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1648",
        "exp_2471"
      ],
      "cosine_similarity": 0.8437252278741498,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_824",
        "exp_2471"
      ],
      "cosine_similarity": 0.8631470483825763,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6481250000000001
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.47,
      "score_simulation": null,
      "score_embedding": 0.6944000000000001
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5428571428571428,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6056249999999999
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.475,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6056249999999999
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.6944000000000001
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6481250000000001
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.44,
      "score_simulation": null,
      "score_embedding": 0.6944000000000001
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.575,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.6481250000000001
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.6,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.6056249999999999
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}