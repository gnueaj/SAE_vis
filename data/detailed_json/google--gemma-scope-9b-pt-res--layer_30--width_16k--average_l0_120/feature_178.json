{
  "feature_id": 178,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_974",
      "text": "Special characters, symbols, and keywords used in programming languages, markup languages, and other technical contexts, often serving specific syntactic or semantic purposes.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_150",
      "text": "Patterns involving special characters, delimiters, or syntax elements in code, markup, or structured text, often indicating formatting, syntax highlighting, or structural boundaries.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1798",
      "text": "The highlighted tokens are short, keyword‑like or symbolic elements that belong to code or markup syntax—such as language keywords, attribute names, or special symbols—rather than ordinary natural‑language words. They are the syntactic units that directly influence program or document behavior.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_974",
        "exp_150"
      ],
      "cosine_similarity": 0.9104469542021786,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_974",
        "exp_1798"
      ],
      "cosine_similarity": 0.9058950344063847,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_150",
        "exp_1798"
      ],
      "cosine_similarity": 0.8859945372243051,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.6806249999999999
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.57,
      "score_detection": 0.51,
      "score_simulation": null,
      "score_embedding": 0.6076
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.75,
      "score_detection": 0.4666666666666667,
      "score_simulation": null,
      "score_embedding": 0.6531250000000001
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.6531250000000001
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.575,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.6076
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.6806249999999999
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.53,
      "score_detection": 0.43,
      "score_simulation": null,
      "score_embedding": 0.6076
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.63,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.6806249999999999
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.45,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.6531250000000001
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 1.0028226679193606,
      "z_score_fuzz": -0.4868052975950656,
      "z_score_detection": -0.2610867883986837
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.5985659476155943,
      "z_score_fuzz": -0.6125541979591392,
      "z_score_detection": -0.6121216435953923
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.8505863131319107,
      "z_score_fuzz": -0.3839198336608233,
      "z_score_detection": -0.9007503023126858
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.08497686064187042
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.20870329797964574
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.14469460761386613
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}