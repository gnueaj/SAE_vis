{
  "feature_id": 863,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1532",
      "text": "Various tokens including nouns, adjectives, adverbs, and numbers, often representing objects, concepts, or quantities, and sometimes being part of a larger phrase or sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_708",
      "text": "Partial word fragments or sub-words that are part of compound terms, often related to scientific, technical, or domain-specific vocabulary, with activations concentrated on the initial or internal segments of longer words.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2355",
      "text": "The activations repeatedly target sub‑word fragments—often suffixes or prefixes that mark morphological boundaries—as well as whole nouns that carry key semantic content, indicating the model focuses on these units to capture meaning and structure.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1532",
        "exp_708"
      ],
      "cosine_similarity": 0.8507625658936379,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1532",
        "exp_2355"
      ],
      "cosine_similarity": 0.8533446716955364,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_708",
        "exp_2355"
      ],
      "cosine_similarity": 0.8899155842993274,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5142857142857142,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.475
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.56,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.41640000000000005
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.625,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.545
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.545
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5666666666666667,
      "score_detection": 0.43333333333333335,
      "score_simulation": null,
      "score_embedding": 0.41640000000000005
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.475
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.61,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.41640000000000005
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.475
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.545
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.13549007583225914,
      "z_score_fuzz": -0.6370507369911024,
      "z_score_detection": -0.5302135107161605
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.45989190821569914,
      "z_score_fuzz": -0.4715630066418444,
      "z_score_detection": -0.616022030875356
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 0.25202064544488845,
      "z_score_fuzz": -0.8411885622574552,
      "z_score_detection": -0.5302135107161605
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.43425144117984066
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.5158256485776332
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.37312714250957574
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}