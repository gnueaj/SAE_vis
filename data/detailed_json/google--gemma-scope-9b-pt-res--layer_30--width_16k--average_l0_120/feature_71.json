{
  "feature_id": 71,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_885",
      "text": "Various programming language constructs, including function definitions, conditional statements, loops, assignments, and type definitions, often with a focus on syntax and structure.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_061",
      "text": "The token sequences involving comparison, assignment, and control flow operators (like `=>`, `:=`, `=`, `if`, `then`, `else`, `return`, `in`, `do`, `with`, `case`, `for`, `while`, `match`, `when`, `finally`, `try`, `catch`, `throw`, `and`, `or`, `not`, `as`, `is`, `in`, `of`, `to`, `from`, `with`, `without`, `on`, `off`, `up`, `down`, `left`, `right`, `over`, `under`, `before`, `after`, `during`, `until`, `while`, `unless`, `provided`, `given`, `assuming`, `supposing`, `considering`, `regardless`, `despite`, `although`, `even though`, `since`, `because`, `so`, `thus`, `hence`, `therefore`, `accordingly`, `consequently`, `meanwhile`, `simultaneously`, `subsequently`, `eventually`, `finally`, `ultimately`, `in conclusion`, `to sum up`, `in summary`, `in short`, `in brief`, `in essence`, `in a nutshell`, `in other words`, `that is to say`, `namely`, `specifically`, `particularly`, `especially`, `especially`, `notably`, `significantly`, `remarkably`, `strikingly`, `interestingly`, `curiously`, `surprisingly`, `unexpectedly`, `astonishingly`, `incredibly`, `amazingly`, `incredibly`, `unbelievably`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1709",
      "text": "The highlighted tokens are core syntactic elements that govern program behavior: assignment, comparison, logical operators, controlâ€‘flow keywords, and function/closure delimiters.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_885",
        "exp_061"
      ],
      "cosine_similarity": 0.8734713419745612,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_885",
        "exp_1709"
      ],
      "cosine_similarity": 0.8949425159961223,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_061",
        "exp_1709"
      ],
      "cosine_similarity": 0.9072184530185279,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.56,
      "score_detection": 0.6285714285714286,
      "score_simulation": null,
      "score_embedding": 0.40312499999999996
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.56,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.22080000000000002
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.68,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.29000000000000004
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.29000000000000004
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.575,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.22080000000000002
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.40312499999999996
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.52,
      "score_detection": 0.4631578947368421,
      "score_simulation": null,
      "score_embedding": 0.22080000000000002
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.56,
      "score_detection": 0.5052631578947369,
      "score_simulation": null,
      "score_embedding": 0.40312499999999996
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.65,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.29000000000000004
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.5333805485721872,
      "z_score_fuzz": -0.5668273250994758,
      "z_score_detection": 0.07551956648417446
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -1.542707580812985,
      "z_score_fuzz": -0.6582810708188027,
      "z_score_detection": -0.5813291124377867
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.1596255534932909,
      "z_score_fuzz": -0.029536568998432888,
      "z_score_detection": -0.2961902739183546
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.3415627690624962
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.9274392546898582
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.4951174654700261
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}