{
  "feature_id": 80,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_892",
      "text": "Words related to smoking or nicotine, often appearing in contexts of health, behavior, or addiction.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_068",
      "text": "The token \\\"smoking\\\" and its variants (e.g., \\\"cigarette\\\", \\\"cig\\\", \\\"Nic\\\") are frequently activated in contexts related to health, medical studies, and behavioral habits, often appearing in association with risk factors, treatments, or demographic data.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1716",
      "text": "The highlighted fragments are parts of tobaccoâ€‘related terms (nicotine, cigarette, smoking, cigar, etc.), indicating that the text is focused on smoking or nicotine use.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_892",
        "exp_068"
      ],
      "cosine_similarity": 0.9163597604791921,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_892",
        "exp_1716"
      ],
      "cosine_similarity": 0.9221904858037097,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_068",
        "exp_1716"
      ],
      "cosine_similarity": 0.8919082749183476,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.4,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.67,
      "score_detection": 0.47,
      "score_simulation": 0.40741024274107485,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.3,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5714285714285714,
      "score_detection": 0.42,
      "score_simulation": 0.5802049423265739,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.67,
      "score_detection": 0.48,
      "score_simulation": 0.3953084458434801,
      "score_embedding": 0.38880000000000003
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.57,
      "score_detection": 0.48,
      "score_simulation": 0.13106428395873548,
      "score_embedding": 0.35240000000000005
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.325,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}