{
  "feature_id": 23,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_844",
      "text": "Special characters used as word separators or connectors in technical, mathematical, and programming contexts, often denoting relationships between words or variables.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_020",
      "text": "The underscore \\\"_\\\" and hyphen \\\"-\\\" characters are used as word separators in compound identifiers, often in programming, technical notation, or structured data, with underscores being more common in variable and function names, and hyphens in compound terms or URLs.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1668",
      "text": "The highlighted tokens are nonâ€‘alphabetic symbols that serve as delimiters or operators in code or markup, such as underscores, arrows, hyphens, and punctuation.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_844",
        "exp_020"
      ],
      "cosine_similarity": 0.9019026213127286,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_844",
        "exp_1668"
      ],
      "cosine_similarity": 0.8889629854852101,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_020",
        "exp_1668"
      ],
      "cosine_similarity": 0.8689215190556154,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.75,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.62,
      "score_detection": 0.51,
      "score_simulation": 0.3315937321150161,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6857142857142857,
      "score_detection": 0.5285714285714286,
      "score_simulation": 0.3104403165817691,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.825,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.68,
      "score_detection": 0.48,
      "score_simulation": 0.3112916564488566,
      "score_embedding": 0.4152
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.84,
      "score_detection": 0.48,
      "score_simulation": 0.2974912885538795,
      "score_embedding": 0.3056
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}