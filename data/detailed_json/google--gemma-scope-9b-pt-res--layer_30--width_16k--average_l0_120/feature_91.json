{
  "feature_id": 91,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_901",
      "text": "Nouns and phrases related to food, often describing dishes or ingredients, and sometimes including conjunctions or prepositions connecting them.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_077",
      "text": "The word \\\"and\\\" frequently appears in lists of food items or ingredients, often connecting two or more components of a dish, particularly in culinary descriptions.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1725",
      "text": "The highlighted tokens are mainly food‑related nouns and cooking‑method words (e.g., “beef,” “chips,” “lobster,” “steak,” “salmon,” “seafood,” “baked,” “roasted,” “grilled”) and the linking words that connect them (“and,” “with,” “in”). These form compound dish names or ingredient lists, so the pattern is that important tokens are the building blocks of culinary descriptions.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_901",
        "exp_077"
      ],
      "cosine_similarity": 0.9124853404130684,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_901",
        "exp_1725"
      ],
      "cosine_similarity": 0.9141620929053395,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_077",
        "exp_1725"
      ],
      "cosine_similarity": 0.9031922266405765,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.35,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.40249999999999997
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.52,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.4052
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.675,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.44062500000000004
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.44062500000000004
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.4052
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.425,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.40249999999999997
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.53,
      "score_detection": 0.44,
      "score_simulation": null,
      "score_embedding": 0.4052
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.41,
      "score_detection": 0.43,
      "score_simulation": null,
      "score_embedding": 0.40249999999999997
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.44062500000000004
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.5368404657264474,
      "z_score_fuzz": -1.7328625830208881,
      "z_score_detection": -0.8695472040729786
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.521893623620043,
      "z_score_fuzz": -0.5553956068845605,
      "z_score_detection": -0.5536158343959412
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.3257855193165721,
      "z_score_fuzz": -0.2696026515116657,
      "z_score_detection": -0.41320189231725774
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -1.0464167509401048
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.5436350216335148
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.3361966877151652
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}