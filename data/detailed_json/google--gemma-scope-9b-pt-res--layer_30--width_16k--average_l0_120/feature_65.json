{
  "feature_id": 65,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_880",
      "text": "Verbs or words that indicate actions, changes, or states, often used in formal or written contexts, and sometimes used to introduce or conclude a quotation or statement.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_056",
      "text": "Common function words and particles (such as \\\"to\\\", \\\"in\\\", \\\"with\\\", \\\"of\\\", \\\"and\\\", \\\"than\\\", \\\"like\\\", \\\"er\\\") that serve grammatical or structural roles in sentences, often appearing in contextually significant phrases or constructions.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1704",
      "text": "The highlighted tokens are the semantic anchors of fixed multi‑word expressions or morphological markers that signal comparison. They are usually the core verb or noun that carries the main meaning of an idiom or collocation, or a suffix (e.g., “‑er”) that marks a comparative form.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_880",
        "exp_056"
      ],
      "cosine_similarity": 0.8482486459348265,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_880",
        "exp_1704"
      ],
      "cosine_similarity": 0.8333276197282067,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_056",
        "exp_1704"
      ],
      "cosine_similarity": 0.8525457094281803,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.625,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.450625
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.46599999999999997
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5142857142857142,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.499375
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.499375
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6285714285714286,
      "score_detection": 0.4857142857142857,
      "score_simulation": null,
      "score_embedding": 0.46599999999999997
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.475,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.450625
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.47,
      "score_simulation": null,
      "score_embedding": 0.46599999999999997
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.47,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.450625
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.499375
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.2704268448484085,
      "z_score_fuzz": -0.8526202804723713,
      "z_score_detection": 0.05484458127835328
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.18531288285360667,
      "z_score_fuzz": -0.8330230492468012,
      "z_score_detection": -0.6338523727266172
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.0005533068161094502,
      "z_score_fuzz": -0.522733554841944,
      "z_score_detection": -0.5887193199156124
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.35606751468080877
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.5507294349423416
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.37066872719122196
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}