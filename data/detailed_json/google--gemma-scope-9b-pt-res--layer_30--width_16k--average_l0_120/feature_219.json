{
  "feature_id": 219,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1009",
      "text": "Tokens representing legal terminology, court names, and citations, often used in formal or technical contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_185",
      "text": "Legal citations and court references often include abbreviated court names, case identifiers, and structured formatting with periods, numbers, and parentheses, frequently surrounding key terms like \\\"Supreme Court,\\\" \\\"Appellate Court,\\\" \\\"cert. denied,\\\" and \\\"U.S.\\\"",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1833",
      "text": "The passages repeatedly employ legal citation conventions—case names, court titles, and procedural phrases—often abbreviated (e.g., U.S., S.Ct., L.Ed.) and punctuated in a Bluebook‑style format, with recurring terms such as “cert. denied,” “Supreme Court,” and “Appellate Court.”",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1009",
        "exp_185"
      ],
      "cosine_similarity": 0.9087555228380878,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1009",
        "exp_1833"
      ],
      "cosine_similarity": 0.8988280467168375,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_185",
        "exp_1833"
      ],
      "cosine_similarity": 0.9458720093931668,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.375,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": 0.37875000000000003
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.47,
      "score_detection": 0.44,
      "score_simulation": null,
      "score_embedding": 0.33280000000000004
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.4,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": 0.365
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.365
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.33280000000000004
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.375,
      "score_detection": 0.4,
      "score_simulation": null,
      "score_embedding": 0.37875000000000003
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.43,
      "score_detection": 0.47,
      "score_simulation": null,
      "score_embedding": 0.33280000000000004
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.33,
      "score_detection": 0.41,
      "score_simulation": null,
      "score_embedding": 0.37875000000000003
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.4,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.365
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.6683173175883363,
      "z_score_fuzz": -1.9729286655341194,
      "z_score_detection": -1.2088808974297967
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.9226904267695494,
      "z_score_fuzz": -1.1269815176303504,
      "z_score_detection": -0.6823286146347342
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.7444354949820619,
      "z_score_fuzz": -1.5842502462269823,
      "z_score_detection": -1.1737774119101259
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -1.283375626850751
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.9106668530115446
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -1.16748771770639
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}