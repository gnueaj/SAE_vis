{
  "feature_id": 978,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1627",
      "text": "Common nouns and adjectives, often representing objects, concepts, or ideas, that are integral to the meaning of a sentence or phrase.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_803",
      "text": "Common nouns and adjectives that denote abstract concepts, roles, locations, or measurable attributes, often appearing in contexts involving evaluation, description, or categorization.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2450",
      "text": "The highlighted tokens are words that belong to semantically coherent phrases or concepts—often nouns, adjectives, or key verbs—whose importance is reflected in the activation scores. The pattern is that these tokens form phrases that convey a specific idea or theme, but the boundaries of those phrases vary across examples.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1627",
        "exp_803"
      ],
      "cosine_similarity": 0.9231737876661569,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1627",
        "exp_2450"
      ],
      "cosine_similarity": 0.8638339940772533,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_803",
        "exp_2450"
      ],
      "cosine_similarity": 0.8580233439826948,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.3075
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.49,
      "score_detection": 0.46,
      "score_simulation": null,
      "score_embedding": 0.39759999999999995
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.34562499999999996
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.34562499999999996
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.39759999999999995
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.525,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": 0.3075
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.58,
      "score_detection": 0.42,
      "score_simulation": null,
      "score_embedding": 0.39759999999999995
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.5,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.3075
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.55,
      "score_simulation": null,
      "score_embedding": 0.34562499999999996
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.0627478731740043,
      "z_score_fuzz": -0.49823701580998087,
      "z_score_detection": -0.41320189231725774
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.5639662162158477,
      "z_score_fuzz": -0.738303098323213,
      "z_score_detection": -0.6940297764746247
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.8516929267641296,
      "z_score_fuzz": -0.7268713801082977,
      "z_score_detection": -0.47170770151670893
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.6580622604337477
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.6654330303378951
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.6834240027963787
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}