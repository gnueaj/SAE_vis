{
  "feature_id": 2,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_827",
      "text": "Tokens that are part of proper nouns, names of places, people, or organizations, or words that have a specific time-related meaning, such as \\\"hour\\\" or \\\"hours\\\".",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_003",
      "text": "Fragments of words or proper nouns, often part of compound terms or names, that are split across tokens and activated individually, particularly in contexts involving technical, biological, geographical, or branded terminology.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1651",
      "text": "The highlighted tokens all share the common prefix “hor”, appearing in words such as horse, horseradish, horizontal, horrors, hour, etc. This prefix is the latent feature that the model is detecting as important.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_827",
        "exp_003"
      ],
      "cosine_similarity": 0.8776212492796668,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_827",
        "exp_1651"
      ],
      "cosine_similarity": 0.8538181781753204,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_003",
        "exp_1651"
      ],
      "cosine_similarity": 0.8295454523319424,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.14375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.65,
      "score_detection": 0.77,
      "score_simulation": null,
      "score_embedding": 0.19520000000000004
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.1775
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.65,
      "score_detection": 0.7,
      "score_simulation": null,
      "score_embedding": 0.1775
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.875,
      "score_simulation": null,
      "score_embedding": 0.19520000000000004
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.525,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.14375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.67,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.19520000000000004
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.59,
      "score_detection": 0.56,
      "score_simulation": null,
      "score_embedding": 0.14375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.675,
      "score_detection": 0.7,
      "score_simulation": null,
      "score_embedding": 0.1775
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}