{
  "feature_id": 46,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_862",
      "text": "En dash or hyphen used to indicate a range of values, typically years, pages, or numerical values.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_038",
      "text": "The en dash (â€“) or hyphen (-) is used to indicate ranges, such as dates, page numbers, or numerical intervals, often in academic or formal text.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1686",
      "text": "The highlighted tokens are dash characters that signal a range or connection between two elements, such as years, page numbers, or paired terms.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_distance_pairs": [
    {
      "pair": [
        "exp_862",
        "exp_038"
      ],
      "cosine_distance": 0.05085374699162826,
      "euclidean_distance": null
    },
    {
      "pair": [
        "exp_862",
        "exp_1686"
      ],
      "cosine_distance": 0.08167671584939018,
      "euclidean_distance": null
    },
    {
      "pair": [
        "exp_038",
        "exp_1686"
      ],
      "cosine_distance": 0.09221128138566037,
      "euclidean_distance": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7142857142857143,
      "score_detection": 0.775,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.93,
      "score_detection": 0.76,
      "score_simulation": 0.8020481865558994,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.925,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.9,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8666666666666667,
      "score_detection": 0.8888888888888888,
      "score_simulation": 0.8380368860095542,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.875,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.95,
      "score_detection": 0.73,
      "score_simulation": 0.6360651693859862,
      "score_embedding": 0.5244
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.93,
      "score_detection": 0.78,
      "score_simulation": 0.22826916578962514,
      "score_embedding": 0.6384
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.975,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}