{
  "feature_id": 416,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1166",
      "text": "Punctuation marks, often used to denote the end of a sentence or to separate items in a list, and sometimes used in conjunction with other symbols or formatting to indicate specific types of content, such as code or citations.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_342",
      "text": "Punctuation and delimiter tokens such as parentheses, brackets, quotation marks, and commas are frequently activated in structured or formatted text, often surrounding or separating syntactic elements like citations, code blocks, or metadata.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1989",
      "text": "The highlighted tokens are mainly punctuation and structural delimiters—commas, periods, parentheses, brackets, braces, quotation marks, and similar symbols—that serve to separate, group, or otherwise delineate clauses, lists, or code fragments in the text.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1166",
        "exp_342"
      ],
      "cosine_similarity": 0.8953819393313696,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1166",
        "exp_1989"
      ],
      "cosine_similarity": 0.9037727816481237,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_342",
        "exp_1989"
      ],
      "cosine_similarity": 0.9282237692743989,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7714285714285715,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.7987500000000001
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.58,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.9087999999999999
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.8666666666666667,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.8200000000000001
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.825,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.8200000000000001
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.675,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.9087999999999999
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.7987500000000001
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.81,
      "score_detection": 0.52,
      "score_simulation": null,
      "score_embedding": 0.9087999999999999
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.85,
      "score_detection": 0.72,
      "score_simulation": null,
      "score_embedding": 0.7987500000000001
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.825,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.8200000000000001
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 1.6567470100745474,
      "z_score_fuzz": 0.6939278837455236,
      "z_score_detection": 0.5111898930340737
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 2.26596922259669,
      "z_score_fuzz": 0.27911982280429326,
      "z_score_detection": -0.3663972449576963
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": 1.7743841933193956,
      "z_score_fuzz": 1.3117850348850206,
      "z_score_detection": -0.17917865551945222
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.9539549289513816
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": 0.7262306001477623
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.9689968575616547
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}