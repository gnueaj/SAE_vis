{
  "feature_id": 420,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1170",
      "text": "Special characters and common programming syntax elements, such as operators, access modifiers, and data types, often used in code snippets.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_346",
      "text": "The presence of tokens that form technical or syntactic constructs in programming languages, such as identifiers, operators, type names, and structural symbols, often indicating code structure, variable names, or function calls.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1993",
      "text": "The highlighted tokens are the semantically or syntactically significant elements that drive the meaning or behavior of the text, such as idiomatic phrases, comparative adjectives, or code keywords and identifiers.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1170",
        "exp_346"
      ],
      "cosine_similarity": 0.9092109703754262,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1170",
        "exp_1993"
      ],
      "cosine_similarity": 0.8609793806081173,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_346",
        "exp_1993"
      ],
      "cosine_similarity": 0.893020847602273,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.375,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.20687499999999998
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.38,
      "score_detection": 0.36,
      "score_simulation": null,
      "score_embedding": 0.12320000000000002
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.21375
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.525,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.21375
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.43333333333333335,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.12320000000000002
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.35,
      "score_detection": 0.35,
      "score_simulation": null,
      "score_embedding": 0.20687499999999998
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.43,
      "score_detection": 0.38,
      "score_simulation": null,
      "score_embedding": 0.12320000000000002
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.39,
      "score_detection": 0.39,
      "score_simulation": null,
      "score_embedding": 0.20687499999999998
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.425,
      "score_detection": 0.425,
      "score_simulation": null,
      "score_embedding": 0.21375
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.6197945350099034,
      "z_score_fuzz": -1.8929066380297093,
      "z_score_detection": -1.3141913539888093
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -2.0830082436222646,
      "z_score_fuzz": -1.5994925371802036,
      "z_score_detection": -1.3141913539888093
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.5817354463130406,
      "z_score_fuzz": -1.1269815176303504,
      "z_score_detection": -0.764236747513966
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -1.6089641756761406
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -1.6655640449304256
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -1.157651237152452
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}