{
  "feature_id": 986,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1635",
      "text": "Mathematical expressions and equations, often involving exponentiation, summation, and other mathematical operations, with a focus on notation and formatting.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_811",
      "text": "Mathematical and symbolic expressions involving superscripts, subscripts, and special operators, often indicating mathematical operations or structural relationships.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2458",
      "text": "The highlighted tokens are those that belong to mathematical or code syntax—LaTeX commands, variable names, and structural punctuation—indicating that the model focuses on the formal elements of the expression rather than ordinary prose.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1635",
        "exp_811"
      ],
      "cosine_similarity": 0.9207804572060889,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1635",
        "exp_2458"
      ],
      "cosine_similarity": 0.8590590793767334,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_811",
        "exp_2458"
      ],
      "cosine_similarity": 0.8558966298518453,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.5375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.51,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.6164
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6285714285714286,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.33125
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.5,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.33125
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5428571428571428,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.6164
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.6,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.5375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.53,
      "score_detection": 0.47,
      "score_simulation": null,
      "score_embedding": 0.6164
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.5375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.525,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.33125
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": 0.2105016395937652,
      "z_score_fuzz": -0.3267612425862445,
      "z_score_detection": -0.6472251291150637
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": 0.6472815811475782,
      "z_score_fuzz": -0.823224433634016,
      "z_score_detection": -0.5419146725560511
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.931271021312115,
      "z_score_fuzz": -0.6615472760230647,
      "z_score_detection": -0.5887193199156117
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.25449491070251434
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.23928584168082964
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.7271792057502638
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}