{
  "feature_id": 574,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1298",
      "text": "Verbs or words related to expressions of strong emotions, particularly sadness, grief, or pain, often describing a person's reaction to a situation.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_474",
      "text": "The root morphemes \\\"cry\\\", \\\"tear\\\", \\\"sob\\\", and \\\"wail\\\" are associated with emotional expression, particularly sadness or distress, often appearing in contexts involving intense feelings, physical reactions like crying or blurred vision, or metaphorical extensions of emotional states.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2121",
      "text": "The model consistently flags short substrings that belong to emotionally charged or actionâ€‘oriented words, often appearing as incomplete fragments of larger terms.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_distance_pairs": [
    {
      "pair": [
        "exp_1298",
        "exp_474"
      ],
      "cosine_distance": 0.09601697244218477,
      "euclidean_distance": null
    },
    {
      "pair": [
        "exp_1298",
        "exp_2121"
      ],
      "cosine_distance": 0.18847641330020493,
      "euclidean_distance": null
    },
    {
      "pair": [
        "exp_474",
        "exp_2121"
      ],
      "cosine_distance": 0.1711417642082672,
      "euclidean_distance": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.73,
      "score_detection": 0.78,
      "score_simulation": 0.4618557318962362,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.525,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7375,
      "score_detection": 0.7294117647058823,
      "score_simulation": 0.5403557278002974,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.75,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.8,
      "score_detection": 0.78,
      "score_simulation": -0.02951554899891437,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.73,
      "score_detection": 0.8,
      "score_simulation": 0.518208317975837,
      "score_embedding": 0.824
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.7428571428571429,
      "score_detection": 0.75,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}