{
  "feature_id": 483,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1221",
      "text": "Tokens often represent nouns, names, or words that are part of a larger phrase or sentence, sometimes denoting a specific object, location, or concept, and can be found in various contexts such as scientific, technical, or everyday language.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_397",
      "text": "Common patterns include abbreviations, technical terms, proper nouns, and compound words often appearing in scientific, technical, or formal contexts, with frequent use of suffixes like \\\"er\\\", \\\"ing\\\", \\\"ed\\\", and \\\"re\\\" in morphological variations, and recurring tokens such as \\\"record\\\", \\\"results\\\", \\\"release\\\", \\\"range\\\", \\\"reservoir\\\", \\\"refurbished\\\", \\\"replaced\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE\\\", \\\"RPD\\\", \\\"rs\\\", \\\"Arg\\\", \\\"Rydberg\\\", \\\"ravel\\\", \\\"rm\\\", \\\"uf\\\", \\\"roa\\\", \\\"esta\\\", \\\"urant\\\", \\\"Request\\\", \\\"res\\\", \\\"disrupt\\\", \\\"result\\\", \\\"replace\\\", \\\"refurbished\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE\\\", \\\"RPD\\\", \\\"rs\\\", \\\"Arg\\\", \\\"Rydberg\\\", \\\"ravel\\\", \\\"rm\\\", \\\"uf\\\", \\\"roa\\\", \\\"esta\\\", \\\"urant\\\", \\\"Request\\\", \\\"res\\\", \\\"disrupt\\\", \\\"result\\\", \\\"replace\\\", \\\"refurbished\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE\\\", \\\"RPD\\\", \\\"rs\\\", \\\"Arg\\\", \\\"Rydberg\\\", \\\"ravel\\\", \\\"rm\\\", \\\"uf\\\", \\\"roa\\\", \\\"esta\\\", \\\"urant\\\", \\\"Request\\\", \\\"res\\\", \\\"disrupt\\\", \\\"result\\\", \\\"replace\\\", \\\"refurbished\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2044",
      "text": "The marked spans are the content‑rich tokens or phrases that carry the bulk of a sentence’s meaning—idiomatic expressions, comparative adjectives, nouns or noun phrases that name objects, places, or entities, and technical or domain‑specific terms. They are usually content words (nouns, adjectives, or multi‑word units) rather than function words, and they receive high activation scores because they are key to understanding the text.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1221",
        "exp_397"
      ],
      "cosine_similarity": 0.8539135750290189,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1221",
        "exp_2044"
      ],
      "cosine_similarity": 0.868646177103411,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_397",
        "exp_2044"
      ],
      "cosine_similarity": 0.8293693384580352,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6285714285714286,
      "score_detection": 0.275,
      "score_simulation": null,
      "score_embedding": 0.36750000000000005
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.49,
      "score_simulation": null,
      "score_embedding": 0.4672
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7333333333333333,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.35625
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.575,
      "score_detection": 0.45,
      "score_simulation": null,
      "score_embedding": 0.35625
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.4672
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.25,
      "score_simulation": null,
      "score_embedding": 0.36750000000000005
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.42,
      "score_simulation": null,
      "score_embedding": 0.4672
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.56,
      "score_detection": 0.23,
      "score_simulation": null,
      "score_embedding": 0.36750000000000005
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.725,
      "score_detection": 0.375,
      "score_simulation": null,
      "score_embedding": 0.35625
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.7305958263650206,
      "z_score_fuzz": -0.2957322931457582,
      "z_score_detection": -2.1566750064609095
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.17866984191742682,
      "z_score_fuzz": -0.3267612425862445,
      "z_score_detection": -0.6823286146347342
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.7928743351417051,
      "z_score_fuzz": 0.20671894077649253,
      "z_score_detection": -0.8812483659128687
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -1.0610010419905629
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.3959198997128019
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.48913458675936045
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}