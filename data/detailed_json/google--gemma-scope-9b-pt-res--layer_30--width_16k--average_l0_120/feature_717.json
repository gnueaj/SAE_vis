{
  "feature_id": 717,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1418",
      "text": "Various symbols, mathematical and programming notation, and formatting markers used in academic and technical writing, including LaTeX and HTML syntax.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_594",
      "text": "Various symbols, mathematical and programming notation, and formatting markers used in academic and technical writing, including LaTeX and HTML syntax.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2241",
      "text": "The highlighted items are the core lexical or symbolic elements that give a phrase its meaning or functionâ€”idiomatic noun phrases, comparative suffixes, or structural tokens in code or math notation. They are usually short, often single words or symbols, and appear in contexts where they are the central component of a phrase or syntax.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1418",
        "exp_594"
      ],
      "cosine_similarity": 1.0,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1418",
        "exp_2241"
      ],
      "cosine_similarity": 0.8375561566168462,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_594",
        "exp_2241"
      ],
      "cosine_similarity": 0.8375561566168462,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.23333333333333334,
      "score_detection": 0.3,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.46,
      "score_detection": 0.37,
      "score_simulation": 0.06366507176934152,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5,
      "score_detection": 0.3466666666666667,
      "score_simulation": 0.07862713280356472,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.35,
      "score_detection": 0.275,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.35,
      "score_detection": 0.33,
      "score_simulation": null,
      "score_embedding": null
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.125,
      "score_detection": 0.225,
      "score_simulation": 0.03016135356938203,
      "score_embedding": null
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.325,
      "score_detection": 0.25,
      "score_simulation": null,
      "score_embedding": null
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}