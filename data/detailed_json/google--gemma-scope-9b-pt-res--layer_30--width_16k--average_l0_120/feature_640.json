{
  "feature_id": 640,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1353",
      "text": "Articles, prepositions, and conjunctions, often used to connect words or phrases in technical and scientific contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_529",
      "text": "Fragments of technical or scientific terms, often derived from compound words or abbreviations, where partial tokens (like \\\"el\\\", \\\"sub\\\", \\\"hat\\\", \\\"M\\\", \\\"fiber\\\") are activated due to their role in forming precise domain-specific terminology.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2176",
      "text": "The highlighted fragments are the core lexical items that form meaningful phrases—usually contiguous sequences of nouns, adjectives, prepositions, or punctuation—that carry the main content of the sentence.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1353",
        "exp_529"
      ],
      "cosine_similarity": 0.8765297766583396,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1353",
        "exp_2176"
      ],
      "cosine_similarity": 0.8364882424123918,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_529",
        "exp_2176"
      ],
      "cosine_similarity": 0.8540575060356984,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.55,
      "score_detection": 0.7142857142857143,
      "score_simulation": null,
      "score_embedding": 0.31375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.62,
      "score_detection": 0.72,
      "score_simulation": null,
      "score_embedding": 0.37560000000000004
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.7428571428571429,
      "score_detection": 0.85,
      "score_simulation": null,
      "score_embedding": 0.15437500000000004
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.775,
      "score_detection": 0.8,
      "score_simulation": null,
      "score_embedding": 0.15437500000000004
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.525,
      "score_detection": 0.925,
      "score_simulation": null,
      "score_embedding": 0.37560000000000004
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.45,
      "score_detection": 0.575,
      "score_simulation": null,
      "score_embedding": 0.31375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.72,
      "score_detection": 0.88,
      "score_simulation": null,
      "score_embedding": 0.37560000000000004
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.36,
      "score_detection": 0.64,
      "score_simulation": null,
      "score_embedding": 0.31375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.85,
      "score_detection": 0.85,
      "score_simulation": null,
      "score_embedding": 0.15437500000000004
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}