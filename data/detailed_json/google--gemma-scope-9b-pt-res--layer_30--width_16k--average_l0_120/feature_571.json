{
  "feature_id": 571,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1295",
      "text": "Technical terms and abbreviations in scientific and academic contexts, often related to physics, astronomy, and chemistry.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_471",
      "text": "Compound scientific terms formed by concatenation of root words, often representing specialized concepts in physics, chemistry, or astronomy, with high activation on individual morphemes that together form a technical term.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_2118",
      "text": "The highlighted tokens are domain‑specific scientific terms or fragments of multi‑word technical phrases, typically nouns or adjectives that appear in research contexts across fields such as astrophysics, climate science, and chemistry.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1295",
        "exp_471"
      ],
      "cosine_similarity": 0.8944750402863374,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1295",
        "exp_2118"
      ],
      "cosine_similarity": 0.9004333964754886,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_471",
        "exp_2118"
      ],
      "cosine_similarity": 0.9019221860248072,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.65,
      "score_detection": 0.775,
      "score_simulation": null,
      "score_embedding": 0.271875
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.65,
      "score_detection": 0.53,
      "score_simulation": null,
      "score_embedding": 0.1848
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.9,
      "score_detection": 0.7714285714285715,
      "score_simulation": null,
      "score_embedding": 0.2625
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.7,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.2625
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.6,
      "score_detection": 0.65,
      "score_simulation": null,
      "score_embedding": 0.1848
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.75,
      "score_detection": 0.875,
      "score_simulation": null,
      "score_embedding": 0.271875
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.72,
      "score_detection": 0.6,
      "score_simulation": null,
      "score_embedding": 0.1848
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.82,
      "score_simulation": null,
      "score_embedding": 0.271875
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.9428571428571428,
      "score_detection": 0.7714285714285715,
      "score_simulation": null,
      "score_embedding": 0.2625
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -1.259963150966838,
      "z_score_fuzz": 0.4734590324578618,
      "z_score_detection": 1.8568235046214556
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -1.7419988088983753,
      "z_score_fuzz": 0.061917176720892586,
      "z_score_detection": 0.24206317071659816
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -1.3118619082807417,
      "z_score_fuzz": 1.3716654636298173,
      "z_score_detection": 1.1497390105823722
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": 0.3567731287041598
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.47933948715362823
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": 0.4031808553104826
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}