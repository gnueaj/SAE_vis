{
  "feature_id": 324,
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "explanations": [
    {
      "explanation_id": "exp_1096",
      "text": "Prepositions and articles often precede nouns, and commas are used to separate items in lists.",
      "explanation_method": "quantiles",
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "data_source": "llama_e-llama_s"
    },
    {
      "explanation_id": "exp_272",
      "text": "Common prepositional phrases and articles (like \\\"at\\\", \\\"in\\\", \\\"on\\\", \\\"the\\\", \\\"a\\\", \\\"and\\\", \\\"of\\\") used to link locations, objects, or concepts in descriptive or spatial contexts.",
      "explanation_method": "quantiles",
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "data_source": "gwen_e-llama_s"
    },
    {
      "explanation_id": "exp_1919",
      "text": "The highlighted tokens are almost always very short, highâ€‘frequency function words or punctuation marks that act as grammatical glue (articles, prepositions, conjunctions, commas, question marks, etc.), with a few short nouns or noun phrases that anchor the meaning of a clause.",
      "explanation_method": "quantiles",
      "llm_explainer": "openai/gpt-oss-20b",
      "data_source": "openai_e-llama_s"
    }
  ],
  "semantic_similarity_pairs": [
    {
      "pair": [
        "exp_1096",
        "exp_272"
      ],
      "cosine_similarity": 0.8639824264479161,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_1096",
        "exp_1919"
      ],
      "cosine_similarity": 0.8380744345762766,
      "euclidean_similarity": null
    },
    {
      "pair": [
        "exp_272",
        "exp_1919"
      ],
      "cosine_similarity": 0.8481704647344217,
      "euclidean_similarity": null
    }
  ],
  "scores": [
    {
      "data_source": "gwen_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.675,
      "score_detection": 0.5,
      "score_simulation": null,
      "score_embedding": 0.369375
    },
    {
      "data_source": "llama_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.41,
      "score_detection": 0.39,
      "score_simulation": null,
      "score_embedding": 0.452
    },
    {
      "data_source": "openai_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.4666666666666667,
      "score_detection": 0.4666666666666667,
      "score_simulation": null,
      "score_embedding": 0.34437500000000004
    },
    {
      "data_source": "openai_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.55,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.34437500000000004
    },
    {
      "data_source": "llama_e-openai_s",
      "llm_scorer": "openai/gpt-oss-20b",
      "score_fuzz": 0.5428571428571428,
      "score_detection": 0.3142857142857143,
      "score_simulation": null,
      "score_embedding": 0.452
    },
    {
      "data_source": "gwen_e-gwen_s",
      "llm_scorer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "score_fuzz": 0.625,
      "score_detection": 0.475,
      "score_simulation": null,
      "score_embedding": 0.369375
    },
    {
      "data_source": "llama_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.64,
      "score_detection": 0.34,
      "score_simulation": null,
      "score_embedding": 0.452
    },
    {
      "data_source": "gwen_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.55,
      "score_detection": 0.39,
      "score_simulation": null,
      "score_embedding": 0.369375
    },
    {
      "data_source": "openai_e-llama_s",
      "llm_scorer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "score_fuzz": 0.75,
      "score_detection": 0.625,
      "score_simulation": null,
      "score_embedding": 0.34437500000000004
    }
  ],
  "normalized_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "z_score_embedding": -0.72021607490224,
      "z_score_fuzz": -0.2124440604370861,
      "z_score_detection": -0.7291332619942952
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "z_score_embedding": -0.26281502710903587,
      "z_score_fuzz": -0.8003609972041846,
      "z_score_detection": -1.479679214295829
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "z_score_embedding": -0.8586127610726496,
      "z_score_fuzz": -0.40297269735234953,
      "z_score_detection": 0.09384845407798818
    }
  ],
  "overall_scores": [
    {
      "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
      "overall_score": -0.5539311324445405
    },
    {
      "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
      "overall_score": -0.8476184128696831
    },
    {
      "llm_explainer": "openai/gpt-oss-20b",
      "overall_score": -0.38924566811567024
    }
  ],
  "activating_examples": "TODO: Not implemented yet"
}