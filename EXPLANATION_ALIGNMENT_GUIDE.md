# ğŸ” Explanation Alignment ì‹œê°í™” ê°€ì´ë“œ

LLM explanation ê°„ ê³µí†µ êµ¬ë¬¸ì„ ì°¾ì•„ ì‹œê°í™”í•˜ëŠ” ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨
1. [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
2. [ë°ì´í„° ì „ì²˜ë¦¬](#ë°ì´í„°-ì „ì²˜ë¦¬)
3. [ì‹œê°í™” ë°ëª¨](#ì‹œê°í™”-ë°ëª¨)
4. [ê³ ê¸‰ ì‚¬ìš©ë²•](#ê³ ê¸‰-ì‚¬ìš©ë²•)

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### Step 1: ë°ì´í„° ì „ì²˜ë¦¬

```bash
# ë°ì´í„°ëŠ” ì´ë¯¸ ì „ì²˜ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤! âœ…
# data/explanation_alignment/alignment_exact.json (6.2MB)
# data/explanation_alignment/alignment_semantic.json (3.4MB)
```

### Step 2: ì‹œê°í™” í™•ì¸

```bash
cd frontend

# ë°ëª¨ ì„œë²„ ì‹¤í–‰
python3 serve_demo.py

# ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°
# http://localhost:8081/explanation_alignment_demo.html
```

ë! ğŸ‰

---

## ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬

### Exact Matching (N-gram ê¸°ë°˜)

**íŠ¹ì§•:**
- âœ… ë§¤ìš° ë¹ ë¦„ (~2,000 features/sec)
- âœ… ì •í™•í•œ ë¬¸êµ¬ ë§¤ì¹­
- âœ… ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆí•„ìš”
- âŒ í‘œí˜„ì´ ë‹¤ë¥´ë©´ ê°ì§€ ëª»í•¨

**ì˜ˆì‹œ:**
```
Llama:  "function words and prepositions"
Qwen:   "function words and prepositions"  â† ë§¤ì¹­ë¨!
OpenAI: "grammatical function words"       â† ë§¤ì¹­ ì•ˆ ë¨
```

**ì‹¤í–‰ ëª…ë ¹:**
```bash
# ì „ì²´ 824 features ì²˜ë¦¬ (ì´ë¯¸ ì™„ë£Œë¨ âœ…)
python3 preprocess_explanation_alignment.py --mode exact

# íŒŒë¼ë¯¸í„° ì¡°ì • (ì¬ì²˜ë¦¬ ì‹œ)
python3 preprocess_explanation_alignment.py \
  --mode exact \
  --min-ngram 3 \     # ìµœì†Œ 3ë‹¨ì–´ êµ¬ë¬¸
  --max-ngram 7 \     # ìµœëŒ€ 7ë‹¨ì–´ êµ¬ë¬¸
  --min-occurrences 2 # 2ê°œ ì´ìƒ LLMì—ì„œ ê³µí†µ
```

---

### Semantic Similarity (ì„ë² ë”© ê¸°ë°˜)

**íŠ¹ì§•:**
- âœ… ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ êµ¬ë¬¸ ê°ì§€
- âœ… í‘œí˜„ì´ ë‹¬ë¼ë„ ë§¤ì¹­ ê°€ëŠ¥
- âœ… ìœ ì‚¬ë„ ì ìˆ˜ ì œê³µ
- âŒ ëŠë¦¼ (~10-20 features/sec)
- âŒ sentence-transformers ì„¤ì¹˜ í•„ìš”

**ì˜ˆì‹œ:**
```
Llama:  "function words and prepositions"
Qwen:   "grammatical function words"       â† ë§¤ì¹­ë¨! (similarity: 0.85)
OpenAI: "high-frequency grammatical words" â† ë§¤ì¹­ë¨! (similarity: 0.78)
```

**ì‹¤í–‰ ëª…ë ¹:**
```bash
# 1. ë¨¼ì € ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
python3 -m pip install sentence-transformers

# 2. Semantic matching ì‹¤í–‰ (ì „ì²´ 824 features, ì´ë¯¸ ì™„ë£Œë¨ âœ…)
python3 preprocess_explanation_alignment.py \
  --mode semantic \
  --threshold 0.7   # 70% ì´ìƒ ìœ ì‚¬ë„

# 3. Threshold ì¡°ì • ì‹¤í—˜ (ì¬ì²˜ë¦¬ ì‹œ)
# 0.7 = ëŠìŠ¨í•œ ë§¤ì¹­ (ë” ë§ì€ ë§¤ì¹­)
# 0.8 = ì¤‘ê°„
# 0.9 = ì—„ê²©í•œ ë§¤ì¹­ (ë§¤ìš° ìœ ì‚¬í•œ ê²ƒë§Œ)
python3 preprocess_explanation_alignment.py \
  --mode semantic \
  --threshold 0.8
```

---

## ğŸ¨ ì‹œê°í™” ë°ëª¨

### ë°©ë²• 1: ê°„ë‹¨í•œ HTTP ì„œë²„

```bash
cd frontend
python serve_demo.py

# ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°:
# http://localhost:8081/explanation_alignment_demo.html
```

### ë°©ë²• 2: Python ê¸°ë³¸ ì„œë²„

```bash
cd frontend
python -m http.server 8081

# ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°:
# http://localhost:8081/explanation_alignment_demo.html
```

### ë°©ë²• 3: ì§ì ‘ íŒŒì¼ ì—´ê¸°

```bash
# macOS
open frontend/explanation_alignment_demo.html

# Linux
xdg-open frontend/explanation_alignment_demo.html

# Windows
start frontend/explanation_alignment_demo.html
```

---

## ğŸ¯ ë°ëª¨ ì‚¬ìš©ë²•

### ì£¼ìš” ê¸°ëŠ¥

1. **ëª¨ë“œ ì „í™˜**
   - "Exact Matching" ë²„íŠ¼: N-gram ê¸°ë°˜ ì •í™•í•œ ë§¤ì¹­
   - "Semantic Similarity" ë²„íŠ¼: ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ì  ìœ ì‚¬ë„

2. **Feature ì„ íƒ**
   - ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì—ì„œ Feature ID ì„ íƒ
   - Previous/Next ë²„íŠ¼ìœ¼ë¡œ íƒìƒ‰

3. **ìƒ‰ìƒ ì½”ë”©**
   - **ì§„í•œ ë…¹ìƒ‰**: 3ê°œ ëª¨ë‘ ê³µí†µ / ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„ (0.9+)
   - **ì¤‘ê°„ ë…¹ìƒ‰**: 2ê°œ ê³µí†µ / ë†’ì€ ìœ ì‚¬ë„ (0.8-0.9)
   - **ì—°í•œ ë…¹ìƒ‰**: ì¤‘ê°„ ìœ ì‚¬ë„ (0.7-0.8)

4. **ìƒì„¸ ì •ë³´**
   - í•˜ì´ë¼ì´íŠ¸ëœ í…ìŠ¤íŠ¸ì— ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ê¸°
   - íˆ´íŒìœ¼ë¡œ ê³µìœ  LLM ìˆ˜, ìœ ì‚¬ë„ ì ìˆ˜ í™•ì¸

5. **í†µê³„ ëŒ€ì‹œë³´ë“œ**
   - Features with Matches: ë§¤ì¹­ì´ ìˆëŠ” feature ê°œìˆ˜
   - Total Features: ì „ì²´ ì²˜ë¦¬ëœ feature ê°œìˆ˜
   - Total Matches: ì „ì²´ ë§¤ì¹­ ê°œìˆ˜

---

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ëŒ€ëŸ‰ ì²˜ë¦¬

ì „ì²´ 824ê°œ feature ì²˜ë¦¬:

```bash
# Exact matching (ë¹ ë¦„ - ì•½ 1ë¶„)
python preprocess_explanation_alignment.py --mode exact

# Semantic matching (ëŠë¦¼ - ì•½ 10-30ë¶„, GPU ìˆìœ¼ë©´ ë” ë¹ ë¦„)
python preprocess_explanation_alignment.py --mode semantic
```

### 2. ë°°ì¹˜ ì²˜ë¦¬

ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬:

```bash
# ì²˜ìŒ 100ê°œ
python preprocess_explanation_alignment.py --mode exact --sample 100
mv data/explanation_alignment/alignment_exact.json \
   data/explanation_alignment/alignment_exact_batch1.json

# ë‹¤ìŒ 100ê°œ (ì½”ë“œ ìˆ˜ì • í•„ìš”)
# TODO: ë°°ì¹˜ offset íŒŒë¼ë¯¸í„° ì¶”ê°€
```

### 3. ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„° íŠœë‹

**Exact matching ìµœì í™”:**

```bash
# ì§§ì€ êµ¬ë¬¸ë§Œ (ë” ë§ì€ ë§¤ì¹­)
python preprocess_explanation_alignment.py \
  --mode exact \
  --min-ngram 2 \
  --max-ngram 3

# ê¸´ êµ¬ë¬¸ë§Œ (ë” ì˜ë¯¸ìˆëŠ” ë§¤ì¹­)
python preprocess_explanation_alignment.py \
  --mode exact \
  --min-ngram 5 \
  --max-ngram 10

# 3ê°œ ëª¨ë‘ ê³µí†µì¸ ê²ƒë§Œ
python preprocess_explanation_alignment.py \
  --mode exact \
  --min-occurrences 3
```

**Semantic matching ìµœì í™”:**

```bash
# ëŠìŠ¨í•œ ë§¤ì¹­ (ë” ë§ì€ ê²°ê³¼)
python preprocess_explanation_alignment.py \
  --mode semantic \
  --threshold 0.6

# ì—„ê²©í•œ ë§¤ì¹­ (ê³ í’ˆì§ˆë§Œ)
python preprocess_explanation_alignment.py \
  --mode semantic \
  --threshold 0.85

# ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë§¤ì¹­
python preprocess_explanation_alignment.py \
  --mode semantic \
  --chunk-method sentence
```

### 4. ì¶œë ¥ ë°ì´í„° êµ¬ì¡°

```json
{
  "statistics": {
    "total_features": 50,
    "mode": "exact",
    "features_with_matches": 20,
    "total_matches": 93
  },
  "results": [
    {
      "feature_id": 0,
      "alignment_mode": "exact",
      "llm_explainers": ["Llama", "Qwen", "OpenAI"],
      "highlighted_explanations": [
        [
          {"text": "normal word", "highlight": false},
          {
            "text": "common phrase here",
            "highlight": true,
            "color": "#2E7D32",
            "shared_with": [0, 1, 2],
            "match_type": "exact",
            "ngram_length": 3
          }
        ]
      ],
      "metadata": {
        "total_common_ngrams": 5,
        "longest_match": 5
      }
    }
  ]
}
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| Mode | Features/sec | 824 features ì†Œìš” ì‹œê°„ | GPU í•„ìš” |
|------|--------------|----------------------|----------|
| Exact | ~2,000 | ~0.5ì´ˆ | âŒ |
| Semantic (CPU) | ~10-20 | ~40-80ì´ˆ | âŒ |
| Semantic (GPU) | ~100+ | ~8ì´ˆ | âœ… |

---

## ğŸ’¡ í™œìš© ì˜ˆì‹œ

### 1. LLM ì¼ê´€ì„± ë¶„ì„

```python
# alignment_exact.json ë¡œë“œ í›„
import json

with open('data/explanation_alignment/alignment_exact.json') as f:
    data = json.load(f)

# 3ê°œ ëª¨ë‘ ê³µí†µì¸ êµ¬ë¬¸ ì¶”ì¶œ
all_common = []
for feature in data['results']:
    for exp in feature['highlighted_explanations']:
        for seg in exp:
            if seg.get('highlight') and len(seg.get('shared_with', [])) == 3:
                all_common.append(seg['text'])

print(f"3ê°œ LLM ëª¨ë‘ ë™ì˜í•˜ëŠ” êµ¬ë¬¸: {len(all_common)}ê°œ")
print(all_common[:10])  # ìƒìœ„ 10ê°œ
```

### 2. Featureë³„ ì¼ê´€ì„± ì ìˆ˜

```python
# ê° featureì˜ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
consistency_scores = {}

for feature in data['results']:
    feature_id = feature['feature_id']
    total_words = 0
    matched_words = 0

    for exp in feature['highlighted_explanations']:
        for seg in exp:
            words = len(seg['text'].split())
            total_words += words
            if seg.get('highlight'):
                matched_words += words

    consistency_scores[feature_id] = matched_words / total_words if total_words > 0 else 0

# ê°€ì¥ ì¼ê´€ì„± ë†’ì€ feature
top_features = sorted(consistency_scores.items(), key=lambda x: x[1], reverse=True)[:10]
print("ê°€ì¥ ì¼ê´€ì„± ë†’ì€ features:", top_features)
```

### 3. LLMë³„ ìš©ì–´ ì„ íƒ íŒ¨í„´

```python
# ê° LLMì´ ë…íŠ¹í•˜ê²Œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ ì¶”ì¶œ
llm_unique_terms = {0: [], 1: [], 2: []}

for feature in data['results']:
    for exp_idx, exp in enumerate(feature['highlighted_explanations']):
        for seg in exp:
            if not seg.get('highlight'):
                # í•˜ì´ë¼ì´íŠ¸ ì•ˆ ëœ = ë…íŠ¹í•œ í‘œí˜„
                llm_unique_terms[exp_idx].append(seg['text'])

print("Llama ë…íŠ¹í•œ ìš©ì–´:", set(llm_unique_terms[0])[:20])
print("Qwen ë…íŠ¹í•œ ìš©ì–´:", set(llm_unique_terms[1])[:20])
print("OpenAI ë…íŠ¹í•œ ìš©ì–´:", set(llm_unique_terms[2])[:20])
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### Q: "sentence-transformers not installed" ê²½ê³ 

**A:** Semantic modeë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜ í•„ìš”:
```bash
pip install sentence-transformers
```

### Q: ë°ëª¨ í˜ì´ì§€ì—ì„œ ë°ì´í„°ê°€ ì•ˆ ë³´ì„

**A:** ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
1. ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í–ˆëŠ”ê°€?
   ```bash
   ls data/explanation_alignment/alignment_*.json
   ```
2. HTTP ì„œë²„ë¥¼ ì‚¬ìš©í–ˆëŠ”ê°€? (íŒŒì¼ ì§ì ‘ ì—´ê¸°ëŠ” CORS ì—ëŸ¬ ë°œìƒ ê°€ëŠ¥)
   ```bash
   python serve_demo.py
   ```

### Q: ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

**A:** ìƒ˜í”Œ í¬ê¸°ë¥¼ ì¤„ì´ì„¸ìš”:
```bash
python preprocess_explanation_alignment.py --mode semantic --sample 20
```

### Q: Semantic modeê°€ ë„ˆë¬´ ëŠë¦¼

**A:**
1. GPU ì‚¬ìš© (CUDA ì„¤ì¹˜)
2. ë˜ëŠ” Exact mode ì‚¬ìš©
3. ë˜ëŠ” ìƒ˜í”Œ í¬ê¸° ì¶•ì†Œ

---

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

- [ ] **API í†µí•©**: FastAPI endpointë¡œ ë§Œë“¤ê¸°
- [ ] **React ì»´í¬ë„ŒíŠ¸**: ë©”ì¸ ì•±ì— í†µí•©
- [ ] **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ì‚¬ìš©ìê°€ threshold ì¡°ì • ì‹œ ì¦‰ì‹œ ì¬ê³„ì‚°
- [ ] **Export ê¸°ëŠ¥**: í•˜ì´ë¼ì´íŠ¸ëœ í…ìŠ¤íŠ¸ PDF/HTMLë¡œ ì €ì¥
- [ ] **Cross-feature ë¶„ì„**: ì „ì²´ featureì— ê±¸ì¹œ í†µê³„

---

## ğŸ“ ë„ì›€ë§

ë¬¸ì œê°€ ìˆìœ¼ë©´:
1. [README_explanation_alignment.md](backend/README_explanation_alignment.md) í™•ì¸
2. ë°ì´í„° ê²½ë¡œì™€ íŒŒì¼ ì¡´ì¬ í™•ì¸
3. Python ë²„ì „ í™•ì¸ (3.8+)

---

**ë§Œë“  ë‚ ì§œ**: 2025-10-18
**ë²„ì „**: 1.0.0
**ìƒíƒœ**: âœ… í”„ë¡œí† íƒ€ì… ì™„ì„±
