# Explanation Alignment Preprocessing

ì—¬ëŸ¬ LLM explanation ê°„ì˜ ê³µí†µ êµ¬ë¬¸ì„ ì°¾ì•„ ì‹œê°í™”í•˜ê¸° ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

## ğŸ“‹ ê°œìš”

SAE featureì— ëŒ€í•´ 3ê°œì˜ LLM (Llama, Qwen, OpenAI)ì´ ìƒì„±í•œ explanation ê°„ì˜ ê³µí†µ ë¶€ë¶„ì„ ì°¾ìŠµë‹ˆë‹¤:

- **Exact Matching**: N-gram ê¸°ë°˜ ì •í™•í•œ ë¬¸êµ¬ ë§¤ì¹­
- **Semantic Similarity**: ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ì  ìœ ì‚¬ êµ¬ë¬¸ ë§¤ì¹­

## ğŸš€ ì‚¬ìš©ë²•

### 1. ê¸°ë³¸ ì‹¤í–‰ (Exact Matching)

```bash
cd backend
python3 preprocess_explanation_alignment.py --mode exact
```

### 2. Semantic Similarity (ì„ë² ë”© ì„¤ì¹˜ í•„ìš”)

```bash
# ë¨¼ì € sentence-transformers ì„¤ì¹˜
python3 -m pip install sentence-transformers

# Semantic mode ì‹¤í–‰ (ì „ì²´ 824 features)
python3 preprocess_explanation_alignment.py --mode semantic --threshold 0.7
```

### 3. ì „ì²´ ì˜µì…˜

```bash
python preprocess_explanation_alignment.py \
  --mode exact \
  --input-dir ../data/detailed_json/google--gemma-scope-9b-pt-res--layer_30--width_16k--average_l0_120 \
  --output-dir ../data/explanation_alignment \
  --min-ngram 3 \
  --max-ngram 5 \
  --min-occurrences 2 \
  --sample 100
```

## ğŸ“Š íŒŒë¼ë¯¸í„° ì„¤ëª…

### ê³µí†µ íŒŒë¼ë¯¸í„°
- `--mode`: `exact` (n-gram) ë˜ëŠ” `semantic` (ì„ë² ë”©)
- `--input-dir`: Feature JSON íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ
- `--output-dir`: ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: `../data/explanation_alignment`)
- `--sample`: ì²˜ë¦¬í•  feature ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©, Noneì´ë©´ ì „ì²´)

### Exact Matching íŒŒë¼ë¯¸í„°
- `--min-ngram`: ìµœì†Œ n-gram í¬ê¸° (ê¸°ë³¸ê°’: 3)
- `--max-ngram`: ìµœëŒ€ n-gram í¬ê¸° (ê¸°ë³¸ê°’: 5)
- `--min-occurrences`: ìµœì†Œ ì¶œí˜„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 2 = 2ê°œ ì´ìƒ LLMì—ì„œ ê³µí†µ)

### Semantic Similarity íŒŒë¼ë¯¸í„°
- `--threshold`: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.7 = 70% ìœ ì‚¬)
- `--chunk-method`: `sentence` (ë¬¸ì¥ ë‹¨ìœ„) ë˜ëŠ” `phrase` (êµ¬ ë‹¨ìœ„, ê¸°ë³¸ê°’)

## ğŸ“ ì¶œë ¥ í˜•ì‹

ì¶œë ¥ íŒŒì¼: `data/explanation_alignment/alignment_{mode}.json`

```json
{
  "statistics": {
    "total_features": 50,
    "mode": "exact",
    "features_with_matches": 20,
    "total_matches": 93
  },
  "results": [
    {
      "feature_id": 0,
      "alignment_mode": "exact",
      "llm_explainers": [
        "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
        "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
        "openai/gpt-oss-20b"
      ],
      "highlighted_explanations": [
        [
          {"text": "word", "highlight": false},
          {
            "text": "common phrase",
            "highlight": true,
            "color": "#2E7D32",
            "shared_with": [0, 1, 2],
            "match_type": "exact",
            "ngram_length": 2
          },
          ...
        ],
        ...
      ],
      "metadata": {
        "total_common_ngrams": 5,
        "longest_match": 5,
        "common_ngrams_list": [...]
      }
    },
    ...
  ]
}
```

## ğŸ¨ ì‹œê°í™” ë°ëª¨

ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ í™•ì¸í•˜ë ¤ë©´ ê°„ë‹¨í•œ HTML ë°ëª¨ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:

```bash
# íŒŒì¼ ê²½ë¡œ: frontend/explanation_alignment_demo.html
# ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°
open frontend/explanation_alignment_demo.html
# ë˜ëŠ”
python -m http.server 8080
# ê·¸ë¦¬ê³  http://localhost:8080/frontend/explanation_alignment_demo.html ì ‘ì†
```

### ë°ëª¨ ê¸°ëŠ¥
- âœ… Exact / Semantic ëª¨ë“œ ì „í™˜
- âœ… Feature ì„ íƒ (ë“œë¡­ë‹¤ìš´)
- âœ… ìƒ‰ìƒ ì½”ë”©ëœ í•˜ì´ë¼ì´íŒ…
  - **ì§„í•œ ë…¹ìƒ‰ (#2E7D32)**: 3ê°œ ëª¨ë‘ ê³µí†µ / ê³ ìœ ì‚¬ë„ (0.9+)
  - **ì¤‘ê°„ ë…¹ìƒ‰ (#66BB6A)**: 2ê°œ ê³µí†µ / ì¤‘ìœ ì‚¬ë„ (0.8-0.9)
  - **ì—°í•œ ë…¹ìƒ‰ (#AED581)**: ì €ìœ ì‚¬ë„ (0.7-0.8)
- âœ… í˜¸ë²„ íˆ´íŒ (ìƒì„¸ ì •ë³´)
- âœ… í†µê³„ ëŒ€ì‹œë³´ë“œ
- âœ… ì´ì „/ë‹¤ìŒ ë„¤ë¹„ê²Œì´ì…˜

## ğŸ” ì˜ˆì‹œ ì¶œë ¥

### Exact Matching ê²°ê³¼ (Feature 0)
```
Llama:   "... a question or explanation about a process ..."
Qwen:    "... a question or explanation about a method ..."
OpenAI:  "... introduces a question ..."

ê³µí†µ êµ¬ë¬¸: "a question or explanation about" (5-gram, 2ê°œ LLM ê³µìœ )
```

### Semantic Similarity ê²°ê³¼
```
Llama:   "function words and prepositions"
Qwen:    "grammatical function words"
OpenAI:  "high-frequency function words"

ì˜ë¯¸ì  ìœ ì‚¬ êµ¬ë¬¸: similarity 0.85+ (ê°™ì€ ê°œë…ì„ ë‹¤ë¥´ê²Œ í‘œí˜„)
```

## ğŸ“ˆ ì„±ëŠ¥

- **Exact Matching**: ë§¤ìš° ë¹ ë¦„ (~2,000 features/sec)
- **Semantic Similarity**: ëŠë¦¼ (~10-20 features/sec, GPU ì‚¬ìš© ì‹œ ë” ë¹ ë¦„)

## ğŸ”§ ì˜ì¡´ì„±

### í•„ìˆ˜
- Python 3.8+
- numpy
- tqdm

### ì„ íƒ (Semantic modeìš©)
```bash
pip install sentence-transformers
```

## ğŸ’¡ í™œìš© ë°©ì•ˆ

1. **LLM Explanation ì¼ê´€ì„± ë¶„ì„**: ì—¬ëŸ¬ LLMì´ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ”ì§€ ì •ëŸ‰í™”
2. **Feature í•´ì„ ê²€ì¦**: 3ê°œ LLMì´ ëª¨ë‘ ë™ì˜í•˜ëŠ” í•µì‹¬ ê°œë… ì¶”ì¶œ
3. **LLM ë¹„êµ ì—°êµ¬**: ê° LLMì˜ ì„¤ëª… ìŠ¤íƒ€ì¼ê³¼ ìš©ì–´ ì„ íƒ ì°¨ì´ ë¶„ì„
4. **Interactive Visualization**: í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸ë¡œ í†µí•©í•˜ì—¬ ì‚¬ìš©ìê°€ ì§ì ‘ íƒìƒ‰

## ğŸ“ ì°¸ê³ ì‚¬í•­

- **ë°ì´í„° ê²½ë¡œ**: ì…ë ¥ ë°ì´í„°ëŠ” `data/detailed_json/...` í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤
- **Feature ê°œìˆ˜**: Feature IDëŠ” 0-999 ë²”ìœ„ì´ì§€ë§Œ, ì‹¤ì œë¡œëŠ” 824ê°œ featureë§Œ ì¡´ì¬í•©ë‹ˆë‹¤
- **Feature êµ¬ì¡°**: ê° featureëŠ” ì •í™•íˆ 3ê°œì˜ explanationì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤ (Llama, Qwen, OpenAI)
  - âš ï¸ Feature 224ëŠ” 2ê°œë§Œ ìˆì–´ì„œ ê²½ê³ ê°€ ë°œìƒí•©ë‹ˆë‹¤ (ì •ìƒ)
- **ë©”ëª¨ë¦¬**: Semantic modeëŠ” ì„ë² ë”© ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ë¯€ë¡œ ~500MB RAM í•„ìš”
- **ì‹œìŠ¤í…œ í†µí•©**: ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©° FastAPI ë°±ì—”ë“œì™€ ë¶„ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- **Python ë²„ì „**: `python3` ëª…ë ¹ì–´ ì‚¬ìš© (pyenv í™˜ê²½)

## ğŸ› ë¬¸ì œ í•´ê²°

### "sentence-transformers not installed" ê²½ê³ 
```bash
python3 -m pip install sentence-transformers
```

### ì¶œë ¥ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ
- ì…ë ¥ í´ë” ê²½ë¡œ í™•ì¸: `--input-dir` ì˜µì…˜
- Feature JSON íŒŒì¼ ì¡´ì¬ í™•ì¸: `ls data/detailed_json/.../feature_*.json`

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
- `--sample` ì˜µì…˜ìœ¼ë¡œ ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
- Semantic mode ëŒ€ì‹  Exact mode ì‚¬ìš©

## ğŸ”§ ìµœê·¼ ë²„ê·¸ ìˆ˜ì • (2025-10-18)

### **ìˆ˜ì •ëœ Semantic Similarity ìƒ‰ìƒ ë¡œì§**

**ë¬¸ì œ**: ê·¸ë£¹ì„ ì‹œì‘í•œ LLMì˜ chunkê°€ í•­ìƒ ìœ ì‚¬ë„ 1.0ìœ¼ë¡œ ì €ì¥ë˜ì–´ ì§„í•œ ë…¹ìƒ‰ìœ¼ë¡œ í‘œì‹œë¨ (ë¶ˆê³µì •)

**ìˆ˜ì •**: ì‹œì‘ chunkë„ ë§¤ì¹­ëœ ë‹¤ë¥¸ chunkë“¤ê³¼ì˜ í‰ê·  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ê³µì •í•˜ê²Œ ìƒ‰ìƒ ë°°ì •

**ì˜ˆì‹œ (Feature 105)**:
```
ìˆ˜ì • ì „:
  Llama "formatting": ì§„í•œ ë…¹ìƒ‰ (#2E7D32) - ìœ ì‚¬ë„ 1.0 âŒ
  Qwen "formatting in code": ì¤‘ê°„ ë…¹ìƒ‰ (#66BB6A) - ìœ ì‚¬ë„ 0.815

ìˆ˜ì • í›„:
  Llama "formatting": ì¤‘ê°„ ë…¹ìƒ‰ (#66BB6A) - ìœ ì‚¬ë„ 0.815 âœ…
  Qwen "formatting in code": ì¤‘ê°„ ë…¹ìƒ‰ (#66BB6A) - ìœ ì‚¬ë„ 0.815 âœ…
```

ì´ì œ ë§¤ì¹­ëœ chunkë“¤ì´ ë™ì¼í•œ ìƒ‰ìƒì„ ê°€ì§€ë¯€ë¡œ ë” ì§ê´€ì ì…ë‹ˆë‹¤!

### **ì•Œë ¤ì§„ ì œí•œì‚¬í•­**

- **Chunk ë¶„í•  ì‹œ êµ¬ë¶„ì ì œê±°**: ì‰¼í‘œì™€ ì ‘ì†ì‚¬ë¡œ ë¶„í• í•˜ë©´ í•´ë‹¹ ê¸°í˜¸ê°€ ì œê±°ë©ë‹ˆë‹¤
  - ì˜ˆ: `"formatting, often"` â†’ `["formatting", "often"]` (ì‰¼í‘œ ì‚¬ë¼ì§)
  - HTMLì—ì„œëŠ” ê³µë°±ìœ¼ë¡œ ì—°ê²°ë˜ë¯€ë¡œ ê°€ë…ì„±ì€ ìœ ì§€ë©ë‹ˆë‹¤

## ğŸ“š ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´

- [ ] Stopword í•„í„°ë§ ì˜µì…˜
- [ ] ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ ì§€ì› (BERT, RoBERTa, etc.)
- [ ] Batch processing for large datasets
- [ ] Export to HTML/PDF with highlighted text
- [ ] Cross-feature aggregation statistics
- [x] ~~Semantic similarity ìƒ‰ìƒ ë²„ê·¸ ìˆ˜ì •~~ (2025-10-18 ì™„ë£Œ)
